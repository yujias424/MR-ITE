{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import dowhy\n",
    "import econml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import shap\n",
    "import statsmodels.nonparametric.smoothers_lowess as sl\n",
    "from econml.grf import CausalForest, CausalIVForest, RegressionForest\n",
    "from econml.iv.dml import DMLIV, NonParamDMLIV, OrthoIV\n",
    "from econml.iv.dr import DRIV, ForestDRIV, LinearDRIV, SparseLinearDRIV\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCV\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy import special\n",
    "from scipy.interpolate import interp1d, interpn\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import (LinearRegression, LogisticRegression,\n",
    "                                  LogisticRegressionCV)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load dataset and sample\n",
    "X_set1 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/04_pheno_covar_data/traits/ukbb.covariate.traits.set1.gz\", sep = \"\\t\")\n",
    "X_set2 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/04_pheno_covar_data/traits/ukbb.covariate.traits.set2.gz\", sep = \"\\t\")\n",
    "X_set3 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/04_pheno_covar_data/IGF1/CAD/ukbb.covariate.IGF1.set3.gz\", sep = \"\\t\")\n",
    "\n",
    "Z_set1 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/06_PRS_calculation/IGF1/CAD/set1/5e-05/IGF1_prs.best\", sep = \" \") # score_constd\n",
    "Z_set2 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/06_PRS_calculation/IGF1/CAD/set2/5e-05/IGF1_prs.best\", sep = \" \") # score_constd\n",
    "Z_set3 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/06_PRS_calculation/IGF1/CAD/set3/5e-05/IGF1_prs.best\", sep = \" \") # score_constd\n",
    "\n",
    "W = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/04_pheno_covar_data/IGF1/CAD/ukbb.phenotype.IGF1.nmolL\", sep = \"\\t\")\n",
    "\n",
    "Y_date1 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date1_james2022.gz\", sep = \"\\t\")\n",
    "Y_date2 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date2_james2022.gz\", sep = \"\\t\")\n",
    "Y_date3 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date3_james2022.gz\", sep = \"\\t\")\n",
    "\n",
    "# harmonize the data\n",
    "selected_id_set3 = set.intersection(set(X_set3['IID']), set(Z_set3['IID']), set(W['IID']), set(Y_date3['IID']) )\n",
    "selected_id_set3 = list(selected_id_set3)\n",
    "selected_id_set3_arr = np.array(selected_id_set3)\n",
    "selected_id_set3_arr.sort()\n",
    "\n",
    "selected_id_set1b = set.intersection(set(X_set1['IID']), set(Z_set1['IID']), set(W['IID']), set(Y_date3['IID']) )\n",
    "selected_id_set1b = list(selected_id_set1b)\n",
    "selected_id_set1b_arr = np.array(selected_id_set1b)\n",
    "selected_id_set1b_arr.sort()\n",
    "\n",
    "# model 1b\n",
    "X_model1b = X_set1.loc[X_set1['IID'].isin(selected_id_set1b)].reset_index(drop = True)\n",
    "Z_model1b = Z_set1.loc[Z_set1['IID'].isin(selected_id_set1b)].reset_index(drop = True)\n",
    "W_model1b = W.loc[W['IID'].isin(selected_id_set1b)].reset_index(drop = True)\n",
    "Y_model1b = Y_date3.loc[Y_date3['IID'].isin(selected_id_set1b)].reset_index(drop = True)\n",
    "\n",
    "# model 3\n",
    "X_model3 = X_set3.loc[X_set3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "Z_model3 = Z_set3.loc[Z_set3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "W_model3 = W.loc[W['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "Y_model3 = Y_date3.loc[Y_date3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "X_model3 = pd.concat([X_model3, Y_model3.loc[:, [\"htn\", \"t2dm\", \"heart_failure\", \"hemorrhage_stroke\", \"ischemic_stroke\"]]], axis=1)\n",
    "Y_model3 = Y_model3.loc[:, [\"IID\", \"CAD\"]]\n",
    "\n",
    "# generate mat file for three models\n",
    "# model 1b\n",
    "W_model1b_mat = W_model1b.loc[:, [\"30770-0.0\"]][\"30770-0.0\"]\n",
    "X_model1b_mat = X_model1b.iloc[:, 2:]\n",
    "Y_model1b_mat = Y_model1b.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model1b_mat = Z_model1b.iloc[:, 3]\n",
    "\n",
    "# model 3\n",
    "W_model3_mat = W_model3.loc[:, [\"30770-0.0\"]][\"30770-0.0\"]\n",
    "X_model3_mat = X_model3.iloc[:, 2:]\n",
    "Y_model3_mat = Y_model3.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model3_mat = Z_model3.iloc[:, 3]\n",
    "\n",
    "# correct the data type\n",
    "X_model1b_mat = X_model1b_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64',\n",
    "})\n",
    "\n",
    "X_model3_mat = X_model3_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \n",
    "    \"4079-0.0\": 'float64', \"4080-0.0\": 'float64', \"189-0.0\": 'float64', \n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"23099-0.0\": 'float64', \"21001-0.0\": 'float64', \"21002-0.0\": 'float64', # \"whr\": 'float64', \n",
    "    \"Blood_pressure_medication\": 'int64', \"Cholesterol_lowering_medication\": 'int64', \"Insulin\": 'int64', \n",
    "    \"Non_alcohol_drinker\": 'int64' , \"Previous_alcohol_drinker\": 'int64', \"Current_alcohol_drinker\": 'int64',\n",
    "    \"Non_smoker\": 'int64' , \"Previous_smoker\": 'int64', \"Current_smoker\": 'int64',\n",
    "    \"30630-0.0\": 'float64', \"30760-0.0\": 'float64', \"30870-0.0\": 'float64', # lipid-related covariates\n",
    "    \"30680-0.0\": 'float64', \"30700-0.0\": 'float64', \"30710-0.0\": 'float64', \"30720-0.0\": 'float64', \"30730-0.0\": 'float64', \n",
    "    \"30740-0.0\": 'float64', \"30750-0.0\": 'float64', \"30650-0.0\": 'float64', \"30660-0.0\": 'float64', \n",
    "    \"30670-0.0\": 'float64', \"30810-0.0\": 'float64', \"30830-0.0\": 'float64', \"30850-0.0\": 'float64', \n",
    "    \"30860-0.0\": 'float64', \"30880-0.0\": 'float64', \"30890-0.0\": 'float64', \"30840-0.0\": 'float64',\n",
    "    \"t2dm\": 'int64', \"htn\": 'int64', \"heart_failure\": 'int64', \"hemorrhage_stroke\": 'int64', \"ischemic_stroke\": 'int64'\n",
    "})\n",
    "\n",
    "# correct the data type\n",
    "X_model1b_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age',\n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "}, inplace=True, axis=1)\n",
    "\n",
    "X_model3_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age', \n",
    "    \"4079-0.0\": 'diastolic blood pressure', \"4080-0.0\": 'systolic blood pressure', \"189-0.0\": 'Townsend deprivation index', \n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "    \"23099-0.0\": 'Body Fat Percentage', \"21001-0.0\": 'BMI', \"21002-0.0\": 'Weight', # \"whr\": 'Waist-hip-ratio', \n",
    "    \"Blood_pressure_medication\": 'Blood pressure medication', \"Cholesterol_lowering_medication\": 'Cholesterol lowering medication', \"Insulin\": 'Insulin', \n",
    "    \"Non_alcohol_drinker\": 'Non-alcohol drinker' , \"Previous_alcohol_drinker\": 'Previous alcohol drinker', \"Current_alcohol_drinker\": 'Current alcohol drinker',\n",
    "    \"Non_smoker\": 'Non-smoker' , \"Previous_smoker\": 'Previous smoker', \"Current_smoker\": 'Current smoker',\n",
    "    \"30630-0.0\": \"Apolipoprotein A\", \"30640-0.0\": \"Apolipoprotein B\", \"30690-0.0\": \"Cholesterol\", \"30760-0.0\": \"HDL-C\", \"30780-0.0\": \"LDL-C\", \"30790-0.0\": \"Lipoprotein A\", \"30870-0.0\": \"Triglycerides\", # lipid-related covariates\n",
    "    \"30680-0.0\": 'Calcium', \"30700-0.0\": 'Creatinine', \"30710-0.0\": 'C-reactive protein', \"30720-0.0\": 'Cystatin C', \"30730-0.0\": 'Gamma glutamyltransferase', \n",
    "    \"30740-0.0\": 'Glucose', \"30750-0.0\": 'HbA1c', \"30650-0.0\": 'Aspartate aminotransferase', \"30660-0.0\": 'Direct bilirubin', \n",
    "    \"30670-0.0\": 'Urea', \"30810-0.0\": 'Phosphate', \"30830-0.0\": 'SHBG', \"30850-0.0\": 'Testosterone', \n",
    "    \"30860-0.0\": 'Total protein', \"30880-0.0\": 'Urate', \"30890-0.0\": 'Vitamin D', \"30840-0.0\": 'Total bilirubin',\n",
    "    \"t2dm\": 'Type 2 diabetes history', \"htn\": 'Hypertension history', \"heart_failure\": 'Heart failure history', \"hemorrhage_stroke\": 'Hemorrhage Stroke history', \"ischemic_stroke\": 'Ischemic Stroke history'\n",
    "}, inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>IID</th>\n",
       "      <th>In_Regression</th>\n",
       "      <th>PRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000048</td>\n",
       "      <td>1000048</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000055</td>\n",
       "      <td>1000055</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.010465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000067</td>\n",
       "      <td>1000067</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.008813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000072</td>\n",
       "      <td>1000072</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.006466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000099</td>\n",
       "      <td>1000099</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276049</th>\n",
       "      <td>6026113</td>\n",
       "      <td>6026113</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.007059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276050</th>\n",
       "      <td>6026124</td>\n",
       "      <td>6026124</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.006450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276051</th>\n",
       "      <td>6026136</td>\n",
       "      <td>6026136</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.002716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276052</th>\n",
       "      <td>6026155</td>\n",
       "      <td>6026155</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276053</th>\n",
       "      <td>6026167</td>\n",
       "      <td>6026167</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.001706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276054 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FID      IID In_Regression       PRS\n",
       "0       1000048  1000048           Yes -0.000462\n",
       "1       1000055  1000055           Yes -0.010465\n",
       "2       1000067  1000067           Yes -0.008813\n",
       "3       1000072  1000072           Yes -0.006466\n",
       "4       1000099  1000099           Yes -0.001012\n",
       "...         ...      ...           ...       ...\n",
       "276049  6026113  6026113           Yes -0.007059\n",
       "276050  6026124  6026124           Yes -0.006450\n",
       "276051  6026136  6026136           Yes -0.002716\n",
       "276052  6026155  6026155           Yes -0.014700\n",
       "276053  6026167  6026167           Yes -0.001706\n",
       "\n",
       "[276054 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>IID</th>\n",
       "      <th>30770-0.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000048</td>\n",
       "      <td>1000048</td>\n",
       "      <td>23.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000055</td>\n",
       "      <td>1000055</td>\n",
       "      <td>20.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000067</td>\n",
       "      <td>1000067</td>\n",
       "      <td>22.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000072</td>\n",
       "      <td>1000072</td>\n",
       "      <td>12.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000099</td>\n",
       "      <td>1000099</td>\n",
       "      <td>22.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276049</th>\n",
       "      <td>6026113</td>\n",
       "      <td>6026113</td>\n",
       "      <td>8.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276050</th>\n",
       "      <td>6026124</td>\n",
       "      <td>6026124</td>\n",
       "      <td>16.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276051</th>\n",
       "      <td>6026136</td>\n",
       "      <td>6026136</td>\n",
       "      <td>21.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276052</th>\n",
       "      <td>6026155</td>\n",
       "      <td>6026155</td>\n",
       "      <td>9.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276053</th>\n",
       "      <td>6026167</td>\n",
       "      <td>6026167</td>\n",
       "      <td>18.043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276054 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FID      IID  30770-0.0\n",
       "0       1000048  1000048     23.993\n",
       "1       1000055  1000055     20.509\n",
       "2       1000067  1000067     22.958\n",
       "3       1000072  1000072     12.205\n",
       "4       1000099  1000099     22.371\n",
       "...         ...      ...        ...\n",
       "276049  6026113  6026113      8.814\n",
       "276050  6026124  6026124     16.788\n",
       "276051  6026136  6026136     21.943\n",
       "276052  6026155  6026155      9.245\n",
       "276053  6026167  6026167     18.043\n",
       "\n",
       "[276054 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_model1b_mat_binary = np.where(W_model1b_mat >= 25, 1, 0)\n",
    "W_model1b_mat_binary = pd.DataFrame({\"30770-0.0\": W_model1b_mat_binary}).iloc[:, 0]\n",
    "W_model3_mat_binary = np.where(W_model3_mat >= 25, 1, 0)\n",
    "W_model3_mat_binary = pd.DataFrame({\"30770-0.0\": W_model3_mat_binary}).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z_model1_mat_binary = np.where(Z_model1_mat <= 0, 1, 0)\n",
    "# Z_model1_mat_binary = pd.DataFrame({\"PRS\": Z_model1_mat_binary}).iloc[:, 0]\n",
    "# Z_model1b_mat_binary = np.where(Z_model1b_mat <= 0, 1, 0)\n",
    "# Z_model1b_mat_binary = pd.DataFrame({\"PRS\": Z_model1b_mat_binary}).iloc[:, 0]\n",
    "# Z_model2_mat_binary = np.where(Z_model2_mat <= 0, 1, 0)\n",
    "# Z_model2_mat_binary = pd.DataFrame({\"PRS\": Z_model2_mat_binary}).iloc[:, 0]\n",
    "# Z_model2b_mat_binary = np.where(Z_model2b_mat <= 0, 1, 0)\n",
    "# Z_model2b_mat_binary = pd.DataFrame({\"PRS\": Z_model2b_mat_binary}).iloc[:, 0]\n",
    "# Z_model3_mat_binary = np.where(Z_model3_mat <= 0, 1, 0)\n",
    "# Z_model3_mat_binary = pd.DataFrame({\"PRS\": Z_model3_mat_binary}).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRIV estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing\n",
    "train, test = train_test_split(X_model1b_mat, test_size=0.5, stratify=Y_model1b_mat, random_state=309)\n",
    "train_set = train.index.to_list()\n",
    "test_set = test.index.to_list()\n",
    "train_set.sort()\n",
    "test_set.sort()\n",
    "\n",
    "# write the training set and testing set to file, which will be used in R analysis.\n",
    "train_set_pd = pd.DataFrame({\"Training_index\": [x+1 for x in train_set], \"Training_id\": selected_id_set1b_arr[train_set]})\n",
    "test_set_pd = pd.DataFrame({\"Testing_index\": [x+1 for x in test_set], \"Testing_id\": selected_id_set1b_arr[test_set]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  276054.000000\n",
      "mean        0.002917\n",
      "std         0.001286\n",
      "min        -0.001951\n",
      "25%         0.002021\n",
      "50%         0.002900\n",
      "75%         0.003801\n",
      "max         0.007801\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model1b = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=300, max_samples=0.03, cv=5, prel_cv = 5, \n",
    "                                         random_state=309, cov_clip = 0.001, n_jobs=40) \n",
    "est_driv_continuousW_model1b.fit(Y_model1b_mat, W_model1b_mat, Z=Z_model1b_mat, X=X_model1b_mat, cache_values=True)\n",
    "point_driv_continuousW_model1b = est_driv_continuousW_model1b.effect(X_model1b_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model1b}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  276054.000000\n",
      "mean        0.003825\n",
      "std         0.001075\n",
      "min        -0.000146\n",
      "25%         0.003068\n",
      "50%         0.003813\n",
      "75%         0.004564\n",
      "max         0.008318\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                  n_estimators=3000, min_samples_leaf=500, max_samples=0.1, cv=5, prel_cv = 5, \n",
    "                                  random_state=309, cov_clip = 0.0015, n_jobs=40) \n",
    "est_driv_continuousW_model3.fit(Y_model3_mat[train_set], W_model3_mat[train_set], Z=Z_model3_mat[train_set], X=X_model3_mat.loc[train_set], cache_values=True)\n",
    "point_driv_continuousW_model3 = est_driv_continuousW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                  n_estimators=3000, min_samples_leaf=200, max_samples=0.03, cv=5, prel_cv = 5, \n",
    "                                  random_state=309, cov_clip = 0.002, n_jobs=40) \n",
    "est_driv_continuousW_model3.fit(Y_model3_mat[train_set], W_model3_mat[train_set], Z=Z_model3_mat[train_set], X=X_model3_mat.loc[train_set], cache_values=True)\n",
    "point_driv_continuousW_model3 = est_driv_continuousW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3\n",
    "point_driv_lb_continuousW_model3, point_driv_ub_continuousW_model3 = est_driv_continuousW_model3.effect_interval(X_model3_mat, alpha=0.1) # type: ignore\n",
    "z_value_driv_continuousW_model3 = point_driv_continuousW_model3/((point_driv_ub_continuousW_model3-point_driv_lb_continuousW_model3)/(2*1.645))\n",
    "p_value_driv_continuousW_model3 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model3)) # * 2\n",
    "p_value_BH_driv_continuousW_model3 = multipletests(pvals = p_value_driv_continuousW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_continuousW_model3, \"upper_bound\": point_driv_ub_continuousW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model3, \"z-value\": z_value_driv_continuousW_model3, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model3, \"p_value_corrected\": p_value_BH_driv_continuousW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2         1000067\n",
      "11        1000219\n",
      "14        1000256\n",
      "16        1000281\n",
      "20        1000330\n",
      "           ...   \n",
      "276026    6025779\n",
      "276031    6025837\n",
      "276045    6026040\n",
      "276049    6026113\n",
      "276052    6026155\n",
      "Name: IID, Length: 81760, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(full_results_continuousW_model3.loc[full_results_continuousW_model3[\"p_value\"] < 0.05, :][\"IID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81736"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(point_driv_lb_continuousW_model3[point_driv_lb_continuousW_model3 > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                  n_estimators=3000, min_samples_leaf=500, max_samples=0.1, cv=5, prel_cv = 5, \n",
    "                                  random_state=309, cov_clip = 0.003, n_jobs=40) \n",
    "est_driv_continuousW_model3.fit(Y_model3_mat, W_model3_mat, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_continuousW_model3 = est_driv_continuousW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_driv_continuousW_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                  n_estimators=3000, min_samples_leaf=500, max_samples=0.1, cv=5, prel_cv = 5, \n",
    "                                  random_state=309, cov_clip = 0.003, n_jobs=40) \n",
    "est_driv_continuousW_model3.fit(Y_model3_mat, W_model3_mat, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_continuousW_model3 = est_driv_continuousW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                  n_estimators=3000, min_samples_leaf=500, max_samples=0.1, cv=5, prel_cv = 5, \n",
    "                                  random_state=309, cov_clip = 0.003, n_jobs=40) \n",
    "est_driv_continuousW_model3.fit(Y_model3_mat, W_model3_mat, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_continuousW_model3 = est_driv_continuousW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model1b = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \n",
    "                                     n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                     random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model1b.fit(Y_model1b_mat, W_model1b_mat_binary, Z=Z_model1b_mat, X=X_model1b_mat, cache_values=True)\n",
    "point_driv_binaryW_model1b = est_driv_binaryW_model1b.effect(X_model1b_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model1b}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Binary W (Full Set)\n",
    "# est_driv_binaryW_model2 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False,\n",
    "#                                      n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "#                                      random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "# est_driv_binaryW_model2.fit(Y_model2_mat, W_model2_mat_binary, Z=Z_model2_mat, X=X_model2_mat, cache_values=True)\n",
    "# point_driv_binaryW_model2 = est_driv_binaryW_model2.effect(X_model2_mat)\n",
    "# print(pd.DataFrame({\"dat\": point_driv_binaryW_model2}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                         random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model3.fit(Y_model3_mat, W_model3_mat_binary, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_binaryW_model3 = est_driv_binaryW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1b\n",
    "point_driv_lb_continuousW_model1b, point_driv_ub_continuousW_model1b = est_driv_continuousW_model1b.effect_interval(X_model1b_mat, alpha=0.1) # type: ignore\n",
    "z_value_driv_continuousW_model1b = point_driv_continuousW_model1b/((point_driv_ub_continuousW_model1b-point_driv_lb_continuousW_model1b)/(2*1.96))\n",
    "p_value_driv_continuousW_model1b = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model1b)) # * 2\n",
    "p_value_BH_driv_continuousW_model1b = multipletests(pvals = p_value_driv_continuousW_model1b, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model1b = pd.DataFrame({\"IID\": selected_id_set1b_arr, \"point\": point_driv_continuousW_model1b, \"upper_bound\": point_driv_ub_continuousW_model1b, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model1b, \"z-value\": z_value_driv_continuousW_model1b, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model1b, \"p_value_corrected\": p_value_BH_driv_continuousW_model1b[1]})\n",
    "\n",
    "# # model 2b\n",
    "# point_driv_lb_continuousW_model2b, point_driv_ub_continuousW_model2b = est_driv_continuousW_model2b.effect_interval(X_model2b_mat, alpha=0.1) # type: ignore\n",
    "# z_value_driv_continuousW_model2b = point_driv_continuousW_model2b/((point_driv_ub_continuousW_model2b-point_driv_lb_continuousW_model2b)/(2*1.96))\n",
    "# p_value_driv_continuousW_model2b = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model2b)) # * 2\n",
    "# p_value_BH_driv_continuousW_model2b = multipletests(pvals = p_value_driv_continuousW_model2b, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "# full_results_continuousW_model2b = pd.DataFrame({\"IID\": selected_id_set2b_arr, \"point\": point_driv_continuousW_model2b, \"upper_bound\": point_driv_ub_continuousW_model2b, \\\n",
    "#                                 \"lower_bound\": point_driv_lb_continuousW_model2b, \"z-value\": z_value_driv_continuousW_model2b, \\\n",
    "#                                 \"p_value\": p_value_driv_continuousW_model2b, \"p_value_corrected\": p_value_BH_driv_continuousW_model2b[1]})\n",
    "\n",
    "# model 3\n",
    "point_driv_lb_continuousW_model3, point_driv_ub_continuousW_model3 = est_driv_continuousW_model3.effect_interval(X_model3_mat, alpha=0.1) # type: ignore\n",
    "z_value_driv_continuousW_model3 = point_driv_continuousW_model3/((point_driv_ub_continuousW_model3-point_driv_lb_continuousW_model3)/(2*1.96))\n",
    "p_value_driv_continuousW_model3 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model3)) # * 2\n",
    "p_value_BH_driv_continuousW_model3 = multipletests(pvals = p_value_driv_continuousW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_continuousW_model3, \"upper_bound\": point_driv_ub_continuousW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model3, \"z-value\": z_value_driv_continuousW_model3, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model3, \"p_value_corrected\": p_value_BH_driv_continuousW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_continuousW_model3.describe()\n",
    "full_results_continuousW_model3.loc[full_results_continuousW_model3[\"p_value\"] < 0.05, :][\"IID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_continuousW_model1b.describe()\n",
    "full_results_continuousW_model1b.loc[full_results_continuousW_model1b[\"p_value\"] < 0.05, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model3_mat_iid = X_model3_mat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model3_mat_iid[\"iid\"] = selected_id_set3_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model3_mat_iid_sig = X_model3_mat_iid.loc[X_model3_mat_iid[\"iid\"].isin(full_results_continuousW_model3.loc[full_results_continuousW_model3[\"p_value\"] < 0.05, :][\"IID\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model3_mat_iid_sig.drop(\"iid\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model3_mat_iid_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_driv_continuousW_model3 = est_driv_continuousW_model3.shap_values(X_model3_mat_iid_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1b\n",
    "point_driv_lb_binaryW_model1b, point_driv_ub_binaryW_model1b = est_driv_binaryW_model1b.effect_interval(X_model1b_mat, alpha=0.1) # type: ignore\n",
    "z_value_driv_binaryW_model1b = point_driv_binaryW_model1b/((point_driv_ub_binaryW_model1b-point_driv_lb_binaryW_model1b)/(2*1.96))\n",
    "p_value_driv_binaryW_model1b = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model1b)) # * 2\n",
    "p_value_BH_driv_binaryW_model1b = multipletests(pvals = p_value_driv_binaryW_model1b, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model1b = pd.DataFrame({\"IID\": selected_id_set1b_arr, \"point\": point_driv_binaryW_model1b, \"upper_bound\": point_driv_ub_binaryW_model1b, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model1b, \"z-value\": z_value_driv_binaryW_model1b, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model1b, \"p_value_corrected\": p_value_BH_driv_binaryW_model1b[1]})\n",
    "\n",
    "# # model 2\n",
    "# point_driv_lb_binaryW_model2b, point_driv_ub_binaryW_model2b = est_driv_binaryW_model2b.effect_interval(X_model2b_mat, alpha=0.05) # type: ignore\n",
    "# z_value_driv_binaryW_model2b = point_driv_binaryW_model2b/((point_driv_ub_binaryW_model2b-point_driv_lb_binaryW_model2b)/(2*1.96))\n",
    "# p_value_driv_binaryW_model2b = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model2b)) # * 2\n",
    "# p_value_BH_driv_binaryW_model2b = multipletests(pvals = p_value_driv_binaryW_model2b, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "# full_results_binaryW_model2b = pd.DataFrame({\"IID\": selected_id_set2b_arr, \"point\": point_driv_binaryW_model2b, \"upper_bound\": point_driv_ub_binaryW_model2b, \\\n",
    "#                                 \"lower_bound\": point_driv_lb_binaryW_model2b, \"z-value\": z_value_driv_binaryW_model2b, \\\n",
    "#                                 \"p_value\": p_value_driv_binaryW_model2b, \"p_value_corrected\": p_value_BH_driv_binaryW_model2b[1]})\n",
    "\n",
    "# model 3\n",
    "point_driv_lb_binaryW_model3, point_driv_ub_binaryW_model3 = est_driv_binaryW_model3.effect_interval(X_model3_mat, alpha=0.1) # type: ignore\n",
    "z_value_driv_binaryW_model3 = point_driv_binaryW_model3/((point_driv_ub_binaryW_model3-point_driv_lb_binaryW_model3)/(2*1.96))\n",
    "p_value_driv_binaryW_model3 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model3)) # * 2\n",
    "p_value_BH_driv_binaryW_model3 = multipletests(pvals = p_value_driv_binaryW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_binaryW_model3, \"upper_bound\": point_driv_ub_binaryW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model3, \"z-value\": z_value_driv_binaryW_model3, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model3, \"p_value_corrected\": p_value_BH_driv_binaryW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_binaryW_model1b.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_driv_binaryW_model3 = est_driv_binaryW_model3.shap_values(X_model3_mat.iloc[1:100, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(shap_values_driv_binaryW_model3['CAD']['30780-0.0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(shap_values_driv_binaryW_model3, \"/home/yujia/Project/2023-07-20-individual_MR/res/02_ITE_analysis/01_table/LDL/CAD/03_variable_importance/driv_binaryW_shap_model3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_loader(filename):\n",
    "    \"\"\" Deserialize a file of pickled objects. \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                yield pickle.load(f)\n",
    "            except EOFError:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = pickle_loader(\"/home/yujia/Project/2023-07-20-individual_MR/res/02_ITE_analysis/01_table/LDL/CAD/03_variable_importance/driv_binaryW_shap_model3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"/home/yujia/Project/2023-07-20-individual_MR/res/02_ITE_analysis/01_table/LDL/CAD/03_variable_importance/driv_binaryW_shap_model3.pkl\", 'rb') as f: #打开文件\n",
    "    t3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3[\"CAD\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab36d0f287787cded7684b4262a0997f97d128972c9ea447e9ce26f1cdffaf94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
