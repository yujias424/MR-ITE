{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yujia/miniconda3/envs/mr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import dowhy\n",
    "import econml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import shap\n",
    "import statsmodels.nonparametric.smoothers_lowess as sl\n",
    "from econml.grf import CausalForest, CausalIVForest, RegressionForest\n",
    "from econml.iv.dml import DMLIV, NonParamDMLIV, OrthoIV\n",
    "from econml.iv.dr import DRIV, ForestDRIV, LinearDRIV, SparseLinearDRIV\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCV\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy import special\n",
    "from scipy.interpolate import interp1d, interpn\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import (LinearRegression, LogisticRegression,\n",
    "                                  LogisticRegressionCV)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and sample\n",
    "X_set1 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/04_pheno_covar_data/traits/ukbb.covariate.traits.set1.gz\", sep = \"\\t\")\n",
    "X_set2 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/04_pheno_covar_data/traits/ukbb.covariate.traits.set2.gz\", sep = \"\\t\")\n",
    "X_set3 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/04_pheno_covar_data/HDL/CAD/ukbb.covariate.HDL.set3.gz\", sep = \"\\t\")\n",
    "\n",
    "Z_set1 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/06_PRS_calculation/HDL/CAD/set1/1e-08/HDL_prs.best\", sep = \" \") # score_constd\n",
    "Z_set2 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/06_PRS_calculation/HDL/CAD/set2/1e-08/HDL_prs.best\", sep = \" \") # score_constd\n",
    "Z_set3 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/06_PRS_calculation/HDL/CAD/set3/1e-08/HDL_prs.best\", sep = \" \") # score_constd\n",
    "\n",
    "W = pd.read_csv(\"~/Project/2023-07-20-individual_MR/dat/04_pheno_covar_data/HDL/CAD/ukbb.phenotype.HDL.mgdL\", sep = \"\\t\")\n",
    "\n",
    "Y_date1 = pd.read_csv(\"~/Project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date1.gz\", sep = \"\\t\")\n",
    "Y_date2 = pd.read_csv(\"~/Project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date2.gz\", sep = \"\\t\")\n",
    "Y_date3 = pd.read_csv(\"~/Project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date3.gz\", sep = \"\\t\")\n",
    "\n",
    "# harmonize the data\n",
    "selected_id_set1 = set.intersection(set(X_set1['IID']), set(Z_set1['IID']), set(W['IID']), set(Y_date1['IID']) )\n",
    "selected_id_set2 = set.intersection(set(X_set2['IID']), set(Z_set2['IID']), set(W['IID']), set(Y_date2['IID']) )\n",
    "selected_id_set3 = set.intersection(set(X_set3['IID']), set(Z_set3['IID']), set(W['IID']), set(Y_date3['IID']) )\n",
    "selected_id_set1 = list(selected_id_set1)\n",
    "selected_id_set2 = list(selected_id_set2)\n",
    "selected_id_set3 = list(selected_id_set3)\n",
    "selected_id_set1_arr = np.array(selected_id_set1)\n",
    "selected_id_set2_arr = np.array(selected_id_set2)\n",
    "selected_id_set3_arr = np.array(selected_id_set3)\n",
    "\n",
    "# model 1\n",
    "X_model1 = X_set1.loc[X_set1['IID'].isin(selected_id_set1)].reset_index(drop = True)\n",
    "Z_model1 = Z_set1.loc[Z_set1['IID'].isin(selected_id_set1)].reset_index(drop = True)\n",
    "W_model1 = W.loc[W['IID'].isin(selected_id_set1)].reset_index(drop = True)\n",
    "Y_model1 = Y_date1.loc[Y_date1['IID'].isin(selected_id_set1)].reset_index(drop = True)\n",
    "\n",
    "# model 2\n",
    "X_model2 = X_set2.loc[X_set2['IID'].isin(selected_id_set2)].reset_index(drop = True)\n",
    "Z_model2 = Z_set2.loc[Z_set2['IID'].isin(selected_id_set2)].reset_index(drop = True)\n",
    "W_model2 = W.loc[W['IID'].isin(selected_id_set2)].reset_index(drop = True)\n",
    "Y_model2 = Y_date2.loc[Y_date2['IID'].isin(selected_id_set2)].reset_index(drop = True)\n",
    "X_model2 = pd.concat([X_model2, Y_model2.loc[:, [\"htn\", \"t2dm\", \"heart_failure\", \"hemorrhage_stroke\", \"ischemic_stroke\"]]], axis=1)\n",
    "Y_model2 = Y_model2.loc[:, [\"IID\", \"CAD\"]]\n",
    "\n",
    "# model 3\n",
    "X_model3 = X_set3.loc[X_set3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "Z_model3 = Z_set3.loc[Z_set3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "W_model3 = W.loc[W['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "Y_model3 = Y_date3.loc[Y_date3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "X_model3 = pd.concat([X_model3, Y_model3.loc[:, [\"htn\", \"t2dm\", \"heart_failure\", \"hemorrhage_stroke\", \"ischemic_stroke\"]]], axis=1)\n",
    "Y_model3 = Y_model3.loc[:, [\"IID\", \"CAD\"]]\n",
    "\n",
    "# generate mat file for three models\n",
    "# model 1\n",
    "W_model1_mat = W_model1.loc[:, [\"30760-0.0\"]][\"30760-0.0\"]\n",
    "X_model1_mat = X_model1.iloc[:, 2:]\n",
    "Y_model1_mat = Y_model1.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model1_mat = Z_model1.iloc[:, 3]\n",
    "\n",
    "# model 2\n",
    "W_model2_mat = W_model2.loc[:, [\"30760-0.0\"]][\"30760-0.0\"]\n",
    "X_model2_mat = X_model2.iloc[:, 2:]\n",
    "Y_model2_mat = Y_model2.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model2_mat = Z_model2.iloc[:, 3]\n",
    "\n",
    "# model 3\n",
    "W_model3_mat = W_model3.loc[:, [\"30760-0.0\"]][\"30760-0.0\"]\n",
    "X_model3_mat = X_model3.iloc[:, 2:]\n",
    "Y_model3_mat = Y_model3.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model3_mat = Z_model3.iloc[:, 3]\n",
    "\n",
    "# correct the data type\n",
    "X_model1_mat = X_model1_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64',\n",
    "})\n",
    "\n",
    "X_model2_mat = X_model2_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \n",
    "    \"4079-0.0\": 'float64', \"4080-0.0\": 'float64', \"189-0.0\": 'float64', \n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"whr\": 'float64', \"23099-0.0\": 'float64', \"21001-0.0\": 'float64', \"21002-0.0\": 'float64',\n",
    "    \"Blood_pressure_medication\": 'int64', \"Cholesterol_lowering_medication\": 'int64', \"No_medication\": 'int64', \"Insulin\": 'int64', \n",
    "    \"Non_alcohol_drinker\": 'int64' , \"Previous_alcohol_drinker\": 'int64', \"Current_alcohol_drinker\": 'int64',\n",
    "    \"Non_smoker\": 'int64' , \"Previous_smoker\": 'int64', \"Current_smoker\": 'int64'\n",
    "})\n",
    "\n",
    "X_model3_mat = X_model3_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \n",
    "    \"4079-0.0\": 'float64', \"4080-0.0\": 'float64', \"189-0.0\": 'float64', \n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"whr\": 'float64', \"23099-0.0\": 'float64', \"21001-0.0\": 'float64', \"21002-0.0\": 'float64',\n",
    "    \"Blood_pressure_medication\": 'int64', \"Cholesterol_lowering_medication\": 'int64', \"No_medication\": 'int64', \"Insulin\": 'int64', \n",
    "    \"Non_alcohol_drinker\": 'int64' , \"Previous_alcohol_drinker\": 'int64', \"Current_alcohol_drinker\": 'int64',\n",
    "    \"Non_smoker\": 'int64' , \"Previous_smoker\": 'int64', \"Current_smoker\": 'int64',\n",
    "    \"30780-0.0\": \"float64\", \"30870-0.0\": \"float64\", \"30640-0.0\": \"float64\", \"30790-0.0\": \"float64\", # lipid-related covariates\n",
    "    \"30680-0.0\": 'float64', \"30700-0.0\": 'float64', \"30710-0.0\": 'float64', \"30720-0.0\": 'float64', \"30730-0.0\": 'float64', \n",
    "    \"30740-0.0\": 'float64', \"30750-0.0\": 'float64', \"30650-0.0\": 'float64', \"30660-0.0\": 'float64', \n",
    "    \"30670-0.0\": 'float64', \"30770-0.0\": 'float64', \"30810-0.0\": 'float64', \"30830-0.0\": 'float64', \"30850-0.0\": 'float64', \n",
    "    \"30860-0.0\": 'float64', \"30880-0.0\": 'float64', \"30890-0.0\": 'float64', \"30840-0.0\": 'float64',\n",
    "    \"t2dm\": 'int64', \"htn\": 'int64', \"heart_failure\": 'int64', \"hemorrhage_stroke\": 'int64', \"ischemic_stroke\": 'int64'\n",
    "})\n",
    "\n",
    "# correct the data type\n",
    "X_model1_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age',\n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "}, inplace=True)\n",
    "\n",
    "X_model2_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age', \n",
    "    \"4079-0.0\": 'diastolic blood pressure', \"4080-0.0\": 'systolic blood pressure', \"189-0.0\": 'Townsend deprivation index', \n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "    \"whr\": 'Waist-hip-ratio', \"23099-0.0\": 'Body Fat Percentage', \"21001-0.0\": 'BMI', \"21002-0.0\": 'Weight',\n",
    "    \"Blood_pressure_medication\": 'Blood pressure medication', \"Cholesterol_lowering_medication\": 'Cholesterol lowering medication', \"No_medication\": 'No medication', \"Insulin\": 'Insulin', \n",
    "    \"Non_alcohol_drinker\": 'Non-alcohol drinker' , \"Previous_alcohol_drinker\": 'Previous alcohol drinker', \"Current_alcohol_drinker\": 'Current alcohol drinker',\n",
    "    \"Non_smoker\": 'Non-smoker' , \"Previous_smoker\": 'Previous smoker', \"Current_smoker\": 'Current smoker'\n",
    "}, inplace=True)\n",
    "\n",
    "X_model3_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age', \n",
    "    \"4079-0.0\": 'diastolic blood pressure', \"4080-0.0\": 'systolic blood pressure', \"189-0.0\": 'Townsend deprivation index', \n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "    \"whr\": 'Waist-hip-ratio', \"23099-0.0\": 'Body Fat Percentage', \"21001-0.0\": 'BMI', \"21002-0.0\": 'Weight',\n",
    "    \"Blood_pressure_medication\": 'Blood pressure medication', \"Cholesterol_lowering_medication\": 'Cholesterol lowering medication', \"No_medication\": 'No medication', \"Insulin\": 'Insulin', \n",
    "    \"Non_alcohol_drinker\": 'Non-alcohol drinker' , \"Previous_alcohol_drinker\": 'Previous alcohol drinker', \"Current_alcohol_drinker\": 'Current alcohol drinker',\n",
    "    \"Non_smoker\": 'Non-smoker' , \"Previous_smoker\": 'Previous smoker', \"Current_smoker\": 'Current smoker',\n",
    "    \"30780-0.0\": \"LDL-C\", \"30870-0.0\": \"Triglycerides\", \"30640-0.0\": \"Apolipoprotein B\", \"30790-0.0\": \"Lipoprotein A\", # lipid-related covariates\n",
    "    \"30680-0.0\": 'Calcium', \"30700-0.0\": 'Creatinine', \"30710-0.0\": 'C-reactive protein', \"30720-0.0\": 'Cystatin C', \"30730-0.0\": 'Gamma glutamyltransferase', \n",
    "    \"30740-0.0\": 'Glucose', \"30750-0.0\": 'HbA1c', \"30650-0.0\": 'Aspartate aminotransferase', \"30660-0.0\": 'Direct bilirubin', \n",
    "    \"30670-0.0\": 'Urea', \"30770-0.0\": '30770-0.0', \"30810-0.0\": '30810-0.0', \"30830-0.0\": 'SHBG', \"30850-0.0\": 'Testosterone', \n",
    "    \"30860-0.0\": 'Total protein', \"30880-0.0\": 'Urate', \"30890-0.0\": 'Vitamin D', \"30840-0.0\": 'Total bilirubin',\n",
    "    \"t2dm\": 'Type 2 diabetes history', \"htn\": 'Hypertension history', \"heart_failure\": 'Heart failure history', \"hemorrhage_stroke\": 'Hemorrhage Stroke history', \"ischemic_stroke\": 'Ischemic Stroke history'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_model1_mat_binary = np.where(W_model1_mat <= 46, 1, 0)\n",
    "W_model1_mat_binary = pd.DataFrame({\"30760-0.0\": W_model1_mat_binary}).iloc[:, 0]\n",
    "W_model2_mat_binary = np.where(W_model2_mat <= 46, 1, 0)\n",
    "W_model2_mat_binary = pd.DataFrame({\"30760-0.0\": W_model2_mat_binary}).iloc[:, 0]\n",
    "W_model3_mat_binary = np.where(W_model3_mat <= 46, 1, 0)\n",
    "W_model3_mat_binary = pd.DataFrame({\"30760-0.0\": W_model3_mat_binary}).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRIV estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing\n",
    "train, test = train_test_split(X_model1_mat, test_size=0.5, stratify=Y_model1_mat, random_state=309)\n",
    "train_set = train.index.to_list()\n",
    "test_set = test.index.to_list()\n",
    "train_set.sort()\n",
    "test_set.sort()\n",
    "\n",
    "# write the training set and testing set to file, which will be used in R analysis.\n",
    "train_set_pd = pd.DataFrame({\"Training_index\": [x+1 for x in train_set], \"Training_id\": selected_id_set1_arr[train_set]})\n",
    "test_set_pd = pd.DataFrame({\"Testing_index\": [x+1 for x in test_set], \"Testing_id\": selected_id_set1_arr[test_set]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  160118.000000\n",
      "mean        0.001716\n",
      "std         0.000565\n",
      "min         0.000543\n",
      "25%         0.001294\n",
      "50%         0.001533\n",
      "75%         0.002054\n",
      "max         0.003722\n",
      "                 dat\n",
      "count  160118.000000\n",
      "mean        0.001717\n",
      "std         0.000564\n",
      "min         0.000556\n",
      "25%         0.001295\n",
      "50%         0.001535\n",
      "75%         0.002055\n",
      "max         0.003652\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Training/Testing Set)\n",
    "est_driv_train_continuousW = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                        n_estimators=5000, min_samples_leaf=50, max_samples=0.02, \n",
    "                                        random_state=309, cov_clip = 1, n_jobs=15)\n",
    "est_driv_train_continuousW.fit(Y_model1_mat[train_set], W_model1_mat[train_set], Z=Z_model1_mat[train_set], X=X_model1_mat.loc[train_set])\n",
    "point_driv_test_continuousW = est_driv_train_continuousW.effect(X_model1_mat.loc[test_set])\n",
    "point_driv_train_continuousW = est_driv_train_continuousW.effect(X_model1_mat.loc[train_set]) \n",
    "print(pd.DataFrame({\"dat\": point_driv_train_continuousW}).describe())\n",
    "print(pd.DataFrame({\"dat\": point_driv_test_continuousW}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  320236.000000\n",
      "mean        0.001523\n",
      "std         0.000464\n",
      "min         0.000632\n",
      "25%         0.001157\n",
      "50%         0.001360\n",
      "75%         0.001861\n",
      "max         0.003109\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model1 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                         random_state=309, n_jobs=15) \n",
    "est_driv_continuousW_model1.fit(Y_model1_mat, W_model1_mat, Z=Z_model1_mat, X=X_model1_mat, cache_values=True)\n",
    "point_driv_continuousW_model1 = est_driv_continuousW_model1.effect(X_model1_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model1}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  293038.000000\n",
      "mean        0.000423\n",
      "std         0.000075\n",
      "min         0.000101\n",
      "25%         0.000373\n",
      "50%         0.000422\n",
      "75%         0.000471\n",
      "max         0.000768\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model2 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                         random_state=309, cov_clip = 10, n_jobs=15) \n",
    "est_driv_continuousW_model2.fit(Y_model2_mat, W_model2_mat, Z=Z_model2_mat, X=X_model2_mat, cache_values=True)\n",
    "point_driv_continuousW_model2 = est_driv_continuousW_model2.effect(X_model2_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model2}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  276141.000000\n",
      "mean        0.000204\n",
      "std         0.000054\n",
      "min        -0.000068\n",
      "25%         0.000171\n",
      "50%         0.000207\n",
      "75%         0.000241\n",
      "max         0.000404\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                  n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                  random_state=309, cov_clip = 5, n_jobs=15) \n",
    "est_driv_continuousW_model3.fit(Y_model3_mat, W_model3_mat, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_continuousW_model3 = est_driv_continuousW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  320236.000000\n",
      "mean       -0.111711\n",
      "std         0.021157\n",
      "min        -0.181154\n",
      "25%        -0.127197\n",
      "50%        -0.108105\n",
      "75%        -0.095302\n",
      "max        -0.058317\n"
     ]
    }
   ],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model1 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \n",
    "                                     n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                     random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model1.fit(Y_model1_mat, W_model1_mat_binary, Z=Z_model1_mat, X=X_model1_mat, cache_values=True)\n",
    "point_driv_binaryW_model1 = est_driv_binaryW_model1.effect(X_model1_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model1}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  293038.000000\n",
      "mean       -0.037975\n",
      "std         0.007564\n",
      "min        -0.069765\n",
      "25%        -0.043007\n",
      "50%        -0.037697\n",
      "75%        -0.032800\n",
      "max        -0.006272\n"
     ]
    }
   ],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model2 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False,\n",
    "                                     n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                     random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model2.fit(Y_model2_mat, W_model2_mat_binary, Z=Z_model2_mat, X=X_model2_mat, cache_values=True)\n",
    "point_driv_binaryW_model2 = est_driv_binaryW_model2.effect(X_model2_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model2}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  276141.000000\n",
      "mean       -0.019493\n",
      "std         0.003342\n",
      "min        -0.034304\n",
      "25%        -0.021752\n",
      "50%        -0.019495\n",
      "75%        -0.017264\n",
      "max        -0.003293\n"
     ]
    }
   ],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                         random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model3.fit(Y_model3_mat, W_model3_mat_binary, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_binaryW_model3 = est_driv_binaryW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_driv_lb_continuousW_model1, point_driv_ub_continuousW_model1 = est_driv_continuousW_model1.effect_interval(X_model1_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_continuousW_model1 = point_driv_continuousW_model1/((point_driv_ub_continuousW_model1-point_driv_lb_continuousW_model1)/(2*1.96))\n",
    "p_value_driv_continuousW_model1 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model1)) # * 2\n",
    "p_value_BH_driv_continuousW_model1 = multipletests(pvals = p_value_driv_continuousW_model1, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model1 = pd.DataFrame({\"IID\": selected_id_set1_arr, \"point\": point_driv_continuousW_model1, \"upper_bound\": point_driv_ub_continuousW_model1, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model1, \"z-value\": z_value_driv_continuousW_model1, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model1, \"p_value_corrected\": p_value_BH_driv_continuousW_model1[1]})\n",
    "\n",
    "# model 2\n",
    "point_driv_lb_continuousW_model2, point_driv_ub_continuousW_model2 = est_driv_continuousW_model2.effect_interval(X_model2_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_continuousW_model2 = point_driv_continuousW_model2/((point_driv_ub_continuousW_model2-point_driv_lb_continuousW_model2)/(2*1.96))\n",
    "p_value_driv_continuousW_model2 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model2)) # * 2\n",
    "p_value_BH_driv_continuousW_model2 = multipletests(pvals = p_value_driv_continuousW_model2, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model2 = pd.DataFrame({\"IID\": selected_id_set2_arr, \"point\": point_driv_continuousW_model2, \"upper_bound\": point_driv_ub_continuousW_model2, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model2, \"z-value\": z_value_driv_continuousW_model2, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model2, \"p_value_corrected\": p_value_BH_driv_continuousW_model2[1]})\n",
    "\n",
    "# model 3\n",
    "point_driv_lb_continuousW_model3, point_driv_ub_continuousW_model3 = est_driv_continuousW_model3.effect_interval(X_model3_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_continuousW_model3 = point_driv_continuousW_model3/((point_driv_ub_continuousW_model3-point_driv_lb_continuousW_model3)/(2*1.96))\n",
    "p_value_driv_continuousW_model3 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model3)) # * 2\n",
    "p_value_BH_driv_continuousW_model3 = multipletests(pvals = p_value_driv_continuousW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_continuousW_model3, \"upper_bound\": point_driv_ub_continuousW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model3, \"z-value\": z_value_driv_continuousW_model3, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model3, \"p_value_corrected\": p_value_BH_driv_continuousW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IID</th>\n",
       "      <th>point</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>z-value</th>\n",
       "      <th>p_value</th>\n",
       "      <th>p_value_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.761410e+05</td>\n",
       "      <td>276141.000000</td>\n",
       "      <td>276141.000000</td>\n",
       "      <td>276141.000000</td>\n",
       "      <td>276141.000000</td>\n",
       "      <td>276141.000000</td>\n",
       "      <td>276141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.515372e+06</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>0.951321</td>\n",
       "      <td>0.185816</td>\n",
       "      <td>0.330274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.451756e+06</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.365499</td>\n",
       "      <td>0.088168</td>\n",
       "      <td>0.017472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000048e+06</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>-0.001159</td>\n",
       "      <td>-0.369979</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.325148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.258302e+06</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.693006</td>\n",
       "      <td>0.118926</td>\n",
       "      <td>0.325148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.515479e+06</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.919238</td>\n",
       "      <td>0.178986</td>\n",
       "      <td>0.325148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.772315e+06</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>1.180372</td>\n",
       "      <td>0.244153</td>\n",
       "      <td>0.325148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.026167e+06</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>3.107085</td>\n",
       "      <td>0.499919</td>\n",
       "      <td>0.499919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                IID          point    upper_bound    lower_bound  \\\n",
       "count  2.761410e+05  276141.000000  276141.000000  276141.000000   \n",
       "mean   3.515372e+06       0.000203       0.000653      -0.000247   \n",
       "std    1.451756e+06       0.000055       0.000136       0.000139   \n",
       "min    1.000048e+06      -0.000094       0.000256      -0.001159   \n",
       "25%    2.258302e+06       0.000169       0.000555      -0.000328   \n",
       "50%    3.515479e+06       0.000206       0.000633      -0.000228   \n",
       "75%    4.772315e+06       0.000240       0.000731      -0.000146   \n",
       "max    6.026167e+06       0.000424       0.001464       0.000141   \n",
       "\n",
       "             z-value        p_value  p_value_corrected  \n",
       "count  276141.000000  276141.000000      276141.000000  \n",
       "mean        0.951321       0.185816           0.330274  \n",
       "std         0.365499       0.088168           0.017472  \n",
       "min        -0.369979       0.000945           0.325148  \n",
       "25%         0.693006       0.118926           0.325148  \n",
       "50%         0.919238       0.178986           0.325148  \n",
       "75%         1.180372       0.244153           0.325148  \n",
       "max         3.107085       0.499919           0.499919  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results_continuousW_model3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_driv_lb_binaryW_model1, point_driv_ub_binaryW_model1 = est_driv_binaryW_model1.effect_interval(X_model1_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model1 = point_driv_binaryW_model1/((point_driv_ub_binaryW_model1-point_driv_lb_binaryW_model1)/(2*1.96))\n",
    "p_value_driv_binaryW_model1 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model1)) # * 2\n",
    "p_value_BH_driv_binaryW_model1 = multipletests(pvals = p_value_driv_binaryW_model1, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model1 = pd.DataFrame({\"IID\": selected_id_set1_arr, \"point\": point_driv_binaryW_model1, \"upper_bound\": point_driv_ub_binaryW_model1, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model1, \"z-value\": z_value_driv_binaryW_model1, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model1, \"p_value_corrected\": p_value_BH_driv_binaryW_model1[1]})\n",
    "\n",
    "# model 2\n",
    "point_driv_lb_binaryW_model2, point_driv_ub_binaryW_model2 = est_driv_binaryW_model2.effect_interval(X_model2_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model2 = point_driv_binaryW_model2/((point_driv_ub_binaryW_model2-point_driv_lb_binaryW_model2)/(2*1.96))\n",
    "p_value_driv_binaryW_model2 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model2)) # * 2\n",
    "p_value_BH_driv_binaryW_model2 = multipletests(pvals = p_value_driv_binaryW_model2, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model2 = pd.DataFrame({\"IID\": selected_id_set2_arr, \"point\": point_driv_binaryW_model2, \"upper_bound\": point_driv_ub_binaryW_model2, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model2, \"z-value\": z_value_driv_binaryW_model2, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model2, \"p_value_corrected\": p_value_BH_driv_binaryW_model2[1]})\n",
    "\n",
    "# model 3\n",
    "point_driv_lb_binaryW_model3, point_driv_ub_binaryW_model3 = est_driv_binaryW_model3.effect_interval(X_model3_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model3 = point_driv_binaryW_model3/((point_driv_ub_binaryW_model3-point_driv_lb_binaryW_model3)/(2*1.96))\n",
    "p_value_driv_binaryW_model3 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model3)) # * 2\n",
    "p_value_BH_driv_binaryW_model3 = multipletests(pvals = p_value_driv_binaryW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_binaryW_model3, \"upper_bound\": point_driv_ub_binaryW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model3, \"z-value\": z_value_driv_binaryW_model3, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model3, \"p_value_corrected\": p_value_BH_driv_binaryW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IID</th>\n",
       "      <th>point</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>z-value</th>\n",
       "      <th>p_value</th>\n",
       "      <th>p_value_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.202360e+05</td>\n",
       "      <td>320236.000000</td>\n",
       "      <td>320236.000000</td>\n",
       "      <td>320236.000000</td>\n",
       "      <td>320236.000000</td>\n",
       "      <td>3.202360e+05</td>\n",
       "      <td>3.202360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.515847e+06</td>\n",
       "      <td>-0.111619</td>\n",
       "      <td>-0.046251</td>\n",
       "      <td>-0.176987</td>\n",
       "      <td>-3.328234</td>\n",
       "      <td>2.716676e-02</td>\n",
       "      <td>2.999731e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.451683e+06</td>\n",
       "      <td>0.070770</td>\n",
       "      <td>0.058821</td>\n",
       "      <td>0.089193</td>\n",
       "      <td>1.749731</td>\n",
       "      <td>6.078643e-02</td>\n",
       "      <td>6.194232e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000048e+06</td>\n",
       "      <td>-0.277574</td>\n",
       "      <td>-0.211310</td>\n",
       "      <td>-0.367703</td>\n",
       "      <td>-9.044005</td>\n",
       "      <td>7.551751e-20</td>\n",
       "      <td>3.956712e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.259791e+06</td>\n",
       "      <td>-0.148466</td>\n",
       "      <td>-0.086228</td>\n",
       "      <td>-0.224229</td>\n",
       "      <td>-4.632318</td>\n",
       "      <td>1.807969e-06</td>\n",
       "      <td>6.882747e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.515574e+06</td>\n",
       "      <td>-0.116495</td>\n",
       "      <td>-0.038144</td>\n",
       "      <td>-0.169104</td>\n",
       "      <td>-2.989419</td>\n",
       "      <td>1.397541e-03</td>\n",
       "      <td>2.750690e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.773627e+06</td>\n",
       "      <td>-0.046164</td>\n",
       "      <td>-0.001489</td>\n",
       "      <td>-0.089802</td>\n",
       "      <td>-2.036315</td>\n",
       "      <td>2.085938e-02</td>\n",
       "      <td>2.723029e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.026167e+06</td>\n",
       "      <td>-0.019099</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>-0.051275</td>\n",
       "      <td>-0.517381</td>\n",
       "      <td>3.024452e-01</td>\n",
       "      <td>3.024452e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                IID          point    upper_bound    lower_bound  \\\n",
       "count  3.202360e+05  320236.000000  320236.000000  320236.000000   \n",
       "mean   3.515847e+06      -0.111619      -0.046251      -0.176987   \n",
       "std    1.451683e+06       0.070770       0.058821       0.089193   \n",
       "min    1.000048e+06      -0.277574      -0.211310      -0.367703   \n",
       "25%    2.259791e+06      -0.148466      -0.086228      -0.224229   \n",
       "50%    3.515574e+06      -0.116495      -0.038144      -0.169104   \n",
       "75%    4.773627e+06      -0.046164      -0.001489      -0.089802   \n",
       "max    6.026167e+06      -0.019099       0.064193      -0.051275   \n",
       "\n",
       "             z-value       p_value  p_value_corrected  \n",
       "count  320236.000000  3.202360e+05       3.202360e+05  \n",
       "mean       -3.328234  2.716676e-02       2.999731e-02  \n",
       "std         1.749731  6.078643e-02       6.194232e-02  \n",
       "min        -9.044005  7.551751e-20       3.956712e-18  \n",
       "25%        -4.632318  1.807969e-06       6.882747e-06  \n",
       "50%        -2.989419  1.397541e-03       2.750690e-03  \n",
       "75%        -2.036315  2.085938e-02       2.723029e-02  \n",
       "max        -0.517381  3.024452e-01       3.024452e-01  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results_binaryW_model1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 97/99 [00:25<00:00]        "
     ]
    }
   ],
   "source": [
    "shap_values_driv_binaryW_model1 = est_driv_binaryW_model1.shap_values(X_model1_mat.iloc[1:100, :])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab36d0f287787cded7684b4262a0997f97d128972c9ea447e9ce26f1cdffaf94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
