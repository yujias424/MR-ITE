{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import dowhy\n",
    "import econml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import shap\n",
    "import statsmodels.nonparametric.smoothers_lowess as sl\n",
    "from econml.grf import CausalForest, CausalIVForest, RegressionForest\n",
    "from econml.iv.dml import DMLIV, NonParamDMLIV, OrthoIV\n",
    "from econml.iv.dr import DRIV, ForestDRIV, LinearDRIV, SparseLinearDRIV\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCV\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy import special\n",
    "from scipy.interpolate import interp1d, interpn\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import (LinearRegression, LogisticRegression,\n",
    "                                  LogisticRegressionCV)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and sample\n",
    "X_set1 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/04_pheno_covar_data/traits/ukbb.covariate.traits.set1.gz\", sep = \"\\t\")\n",
    "X_set2 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/04_pheno_covar_data/traits/ukbb.covariate.traits.set2.gz\", sep = \"\\t\")\n",
    "X_set3 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/04_pheno_covar_data/TG/CAD/ukbb.covariate.TG.set3.gz\", sep = \"\\t\")\n",
    "\n",
    "Z_set1 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/06_PRS_calculation/TG_GLGC_2021/CAD/set1/1e-08/TG_prs.best\", sep = \" \") # score_constd\n",
    "Z_set2 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/06_PRS_calculation/TG_GLGC_2021/CAD/set1/1e-08/TG_prs.best\", sep = \" \") # score_constd\n",
    "Z_set3 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/06_PRS_calculation/TG_GLGC_2021/CAD/set1/1e-08/TG_prs.best\", sep = \" \") # score_constd\n",
    "\n",
    "W = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/04_pheno_covar_data/TG/CAD/ukbb.phenotype.TG.mgdL\", sep = \"\\t\")\n",
    "\n",
    "Y_date1 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date1_james2022.gz\", sep = \"\\t\")\n",
    "Y_date2 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date2_james2022.gz\", sep = \"\\t\")\n",
    "Y_date3 = pd.read_csv(\"/mnt/md0/yujia/project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date3_james2022.gz\", sep = \"\\t\")\n",
    "\n",
    "# harmonize the data\n",
    "selected_id_set3 = set.intersection(set(X_set3['IID']), set(Z_set3['IID']), set(W['IID']), set(Y_date3['IID']) )\n",
    "selected_id_set3 = list(selected_id_set3)\n",
    "selected_id_set3_arr = np.array(selected_id_set3)\n",
    "selected_id_set3_arr.sort()\n",
    "\n",
    "selected_id_set1b = set.intersection(set(X_set1['IID']), set(Z_set1['IID']), set(W['IID']), set(Y_date3['IID']) )\n",
    "selected_id_set1b = list(selected_id_set1b)\n",
    "selected_id_set1b_arr = np.array(selected_id_set1b)\n",
    "selected_id_set1b_arr.sort()\n",
    "\n",
    "# model 1b\n",
    "X_model1b = X_set1.loc[X_set1['IID'].isin(selected_id_set1b)].reset_index(drop = True)\n",
    "Z_model1b = Z_set1.loc[Z_set1['IID'].isin(selected_id_set1b)].reset_index(drop = True)\n",
    "W_model1b = W.loc[W['IID'].isin(selected_id_set1b)].reset_index(drop = True)\n",
    "Y_model1b = Y_date3.loc[Y_date3['IID'].isin(selected_id_set1b)].reset_index(drop = True)\n",
    "\n",
    "# model 3\n",
    "X_model3 = X_set3.loc[X_set3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "Z_model3 = Z_set3.loc[Z_set3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "W_model3 = W.loc[W['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "Y_model3 = Y_date3.loc[Y_date3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "X_model3 = pd.concat([X_model3, Y_model3.loc[:, [\"htn\", \"t2dm\", \"heart_failure\", \"hemorrhage_stroke\", \"ischemic_stroke\"]]], axis=1)\n",
    "Y_model3 = Y_model3.loc[:, [\"IID\", \"CAD\"]]\n",
    "\n",
    "# generate mat file for three models\n",
    "# model 1b\n",
    "W_model1b_mat = W_model1b.loc[:, [\"30870-0.0\"]][\"30870-0.0\"]\n",
    "X_model1b_mat = X_model1b.iloc[:, 2:]\n",
    "Y_model1b_mat = Y_model1b.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model1b_mat = Z_model1b.iloc[:, 3]\n",
    "# model 3\n",
    "W_model3_mat = W_model3.loc[:, [\"30870-0.0\"]][\"30870-0.0\"]\n",
    "X_model3_mat = X_model3.iloc[:, 2:]\n",
    "Y_model3_mat = Y_model3.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model3_mat = Z_model3.iloc[:, 3]\n",
    "\n",
    "# correct the data type\n",
    "X_model1b_mat = X_model1b_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64',\n",
    "})\n",
    "\n",
    "X_model3_mat = X_model3_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \n",
    "    \"4079-0.0\": 'float64', \"4080-0.0\": 'float64', \"189-0.0\": 'float64', \n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"21001-0.0\": 'float64', \"23099-0.0\": 'float64', \"21002-0.0\": 'float64', # \"whr\": 'float64', \n",
    "    \"Blood_pressure_medication\": 'int64', \"Cholesterol_lowering_medication\": 'int64', \"Insulin\": 'int64', # \"No_medication\": 'int64', \n",
    "    \"Non_alcohol_drinker\": 'int64' , \"Previous_alcohol_drinker\": 'int64', \"Current_alcohol_drinker\": 'int64',\n",
    "    \"Non_smoker\": 'int64' , \"Previous_smoker\": 'int64', \"Current_smoker\": 'int64',\n",
    "    \"30630-0.0\": \"float64\", \"30640-0.0\": \"float64\", \"30790-0.0\": \"float64\", \"30780-0.0\": \"float64\", \"30760-0.0\": \"float64\", \"30690-0.0\": \"float64\", # lipid-related covariates\n",
    "    \"30700-0.0\": 'float64', \"30710-0.0\": 'float64', \"30720-0.0\": 'float64', \"30730-0.0\": 'float64', \"30680-0.0\": 'float64', \n",
    "    \"30740-0.0\": 'float64', \"30750-0.0\": 'float64', \"30650-0.0\": 'float64', \"30660-0.0\": 'float64', \n",
    "    \"30670-0.0\": 'float64', \"30770-0.0\": 'float64', \"30810-0.0\": 'float64', \"30830-0.0\": 'float64', \"30850-0.0\": 'float64', \n",
    "    \"30880-0.0\": 'float64', \"30890-0.0\": 'float64', \"30840-0.0\": 'float64', \"30860-0.0\": 'float64', \n",
    "    \"t2dm\": 'int64', \"htn\": 'int64', \"heart_failure\": 'int64', \"hemorrhage_stroke\": 'int64', \"ischemic_stroke\": 'int64'\n",
    "})\n",
    "\n",
    "# correct the data type\n",
    "X_model1b_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age',\n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "}, inplace=True, axis=1)\n",
    "\n",
    "X_model3_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age', \n",
    "    \"4079-0.0\": 'diastolic blood pressure', \"4080-0.0\": 'systolic blood pressure', \"189-0.0\": 'Townsend deprivation index', \n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "    \"21001-0.0\": 'BMI', \"23099-0.0\": 'Body Fat Percentage', \"21002-0.0\": 'Weight', # \"whr\": 'Waist-hip-ratio', \n",
    "    \"Blood_pressure_medication\": 'Blood pressure medication', \"Cholesterol_lowering_medication\": 'Cholesterol lowering medication', \"Insulin\": 'Insulin', # \"No_medication\": 'No medication', \n",
    "    \"Non_alcohol_drinker\": 'Non-alcohol drinker' , \"Previous_alcohol_drinker\": 'Previous alcohol drinker', \"Current_alcohol_drinker\": 'Current alcohol drinker',\n",
    "    \"Non_smoker\": 'Non-smoker' , \"Previous_smoker\": 'Previous smoker', \"Current_smoker\": 'Current smoker',\n",
    "    \"30630-0.0\": \"Apolipoprotein A\", \"30640-0.0\": \"Apolipoprotein B\", \"30790-0.0\": \"Lipoprotein A\", \"30780-0.0\": \"LDL-C\", \"30760-0.0\": \"HDL-C\", \"30690-0.0\": \"Total Cholesterol\", # lipid-related covariates\n",
    "    \"30700-0.0\": 'Creatinine', \"30710-0.0\": 'C-reactive protein', \"30720-0.0\": 'Cystatin C', \"30730-0.0\": 'Gamma glutamyltransferase', \"30680-0.0\": 'Calcium', \n",
    "    \"30740-0.0\": 'Glucose', \"30750-0.0\": 'HbA1c', \"30650-0.0\": 'Aspartate aminotransferase', \"30660-0.0\": 'Direct bilirubin', \n",
    "    \"30670-0.0\": 'Urea', \"30770-0.0\": 'IGF-1', \"30810-0.0\": '30810-0.0', \"30830-0.0\": 'SHBG', \"30850-0.0\": 'Testosterone', \n",
    "    \"30880-0.0\": 'Urate', \"30890-0.0\": 'Vitamin D', \"30840-0.0\": 'Total bilirubin', \"30860-0.0\": 'Total protein', \n",
    "    \"t2dm\": 'Type 2 diabetes history', \"htn\": 'Hypertension history', \"heart_failure\": 'Heart failure history', \"hemorrhage_stroke\": 'Hemorrhage Stroke history', \"ischemic_stroke\": 'Ischemic Stroke history'\n",
    "}, inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Age', 'Genotype batch', 'diastolic blood pressure',\n",
       "       'systolic blood pressure', 'Townsend deprivation index', 'Non-smoker',\n",
       "       'Previous smoker', 'Current smoker', 'Non-alcohol drinker',\n",
       "       'Previous alcohol drinker', 'Current alcohol drinker',\n",
       "       'Cholesterol lowering medication', 'Blood pressure medication',\n",
       "       'Insulin', 'BMI', 'Body Fat Percentage', 'Weight', 'PC1', 'PC2', 'PC3',\n",
       "       'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'Apolipoprotein A',\n",
       "       'Apolipoprotein B', 'Aspartate aminotransferase', 'Direct bilirubin',\n",
       "       'Urea', 'Total Cholesterol', 'Creatinine', 'C-reactive protein',\n",
       "       'Cystatin C', 'Calcium', 'Gamma glutamyltransferase', 'Glucose',\n",
       "       'HbA1c', 'HDL-C', 'IGF-1', 'LDL-C', 'Lipoprotein A', '30810-0.0',\n",
       "       'SHBG', 'Total bilirubin', 'Total protein', 'Testosterone', 'Urate',\n",
       "       'Vitamin D', 'Hypertension history', 'Type 2 diabetes history',\n",
       "       'Heart failure history', 'Hemorrhage Stroke history',\n",
       "       'Ischemic Stroke history'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_model3_mat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Lipid-related Covariates\n",
    "X_model3_mat.drop([\"HDL-C\", \"Apolipoprotein A\", \"Apolipoprotein B\", \"Lipoprotein A\", \"LDL-C\", \"Total Cholesterol\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_model1b_mat_binary = np.where(W_model1b_mat <= 150, 1, 0)\n",
    "W_model1b_mat_binary = pd.DataFrame({\"30870-0.0\": W_model1b_mat_binary}).iloc[:, 0]\n",
    "W_model3_mat_binary = np.where(W_model3_mat <= 150, 1, 0)\n",
    "W_model3_mat_binary = pd.DataFrame({\"30870-0.0\": W_model3_mat_binary}).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRIV estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the dataset into training and testing\n",
    "# train, test = train_test_split(X_model1b_mat, test_size=0.5, stratify=Y_model1b_mat, random_state=309)\n",
    "# train_set = train.index.to_list()\n",
    "# test_set = test.index.to_list()\n",
    "# train_set.sort()\n",
    "# test_set.sort()\n",
    "\n",
    "# # write the training set and testing set to file, which will be used in R analysis.\n",
    "# train_set_pd = pd.DataFrame({\"Training_index\": [x+1 for x in train_set], \"Training_id\": selected_id_set1b_arr[train_set]})\n",
    "# test_set_pd = pd.DataFrame({\"Testing_index\": [x+1 for x in test_set], \"Testing_id\": selected_id_set1b_arr[test_set]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Continuous W (Training/Testing Set)\n",
    "# est_driv_train_continuousW = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "#                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "#                                         random_state=309, cov_clip = 2, n_jobs=15)\n",
    "# est_driv_train_continuousW.fit(Y_model1b_mat[train_set], W_model1b_mat[train_set], Z=Z_model1b_mat[train_set], X=X_model1b_mat.loc[train_set])\n",
    "# point_driv_test_continuousW = est_driv_train_continuousW.effect(X_model1b_mat.loc[test_set])\n",
    "# point_driv_train_continuousW = est_driv_train_continuousW.effect(X_model1b_mat.loc[train_set]) \n",
    "# print(pd.DataFrame({\"dat\": point_driv_train_continuousW}).describe())\n",
    "# print(pd.DataFrame({\"dat\": point_driv_test_continuousW}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  276054.000000\n",
      "mean        0.000082\n",
      "std         0.000026\n",
      "min        -0.000017\n",
      "25%         0.000064\n",
      "50%         0.000081\n",
      "75%         0.000099\n",
      "max         0.000195\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model1 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, cv=5, prel_cv = 5,\n",
    "                                         random_state=309, cov_clip = 0.01, n_jobs=40) \n",
    "est_driv_continuousW_model1.fit(Y_model1b_mat, W_model1b_mat, Z=Z_model1b_mat, X=X_model1b_mat, cache_values=True)\n",
    "point_driv_continuousW_model1 = est_driv_continuousW_model1.effect(X_model1b_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model1}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  276054.000000\n",
      "mean        0.000033\n",
      "std         0.000181\n",
      "min        -0.001679\n",
      "25%        -0.000048\n",
      "50%         0.000061\n",
      "75%         0.000151\n",
      "max         0.000840\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                  n_estimators=5000, min_samples_leaf=100, max_samples=0.02, cv=5, prel_cv = 5,\n",
    "                                  random_state=309, cov_clip = 0.07, n_jobs=40) \n",
    "est_driv_continuousW_model3.fit(Y_model3_mat, W_model3_mat, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_continuousW_model3 = est_driv_continuousW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  276054.000000\n",
      "mean       -0.017502\n",
      "std         0.005070\n",
      "min        -0.036754\n",
      "25%        -0.021012\n",
      "50%        -0.017457\n",
      "75%        -0.013972\n",
      "max         0.001573\n"
     ]
    }
   ],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model1 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \n",
    "                                     n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                     random_state=309, cov_clip = 0.1, n_jobs=40) \n",
    "est_driv_binaryW_model1.fit(Y_model1b_mat, W_model1b_mat_binary, Z=Z_model1b_mat, X=X_model1b_mat, cache_values=True)\n",
    "point_driv_binaryW_model1 = est_driv_binaryW_model1.effect(X_model1b_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model1}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  276054.000000\n",
      "mean       -0.014367\n",
      "std         0.003755\n",
      "min        -0.031108\n",
      "25%        -0.016834\n",
      "50%        -0.014329\n",
      "75%        -0.011864\n",
      "max         0.003353\n"
     ]
    }
   ],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                         random_state=309, cov_clip = 0.1, n_jobs=40) \n",
    "est_driv_binaryW_model3.fit(Y_model3_mat, W_model3_mat_binary, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_binaryW_model3 = est_driv_binaryW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_driv_lb_continuousW_model1, point_driv_ub_continuousW_model1 = est_driv_continuousW_model1.effect_interval(X_model1b_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_continuousW_model1 = point_driv_continuousW_model1/((point_driv_ub_continuousW_model1-point_driv_lb_continuousW_model1)/(2*1.96))\n",
    "p_value_driv_continuousW_model1 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model1)) # * 2\n",
    "p_value_BH_driv_continuousW_model1 = multipletests(pvals = p_value_driv_continuousW_model1, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model1 = pd.DataFrame({\"IID\": selected_id_set1b_arr, \"point\": point_driv_continuousW_model1, \"upper_bound\": point_driv_ub_continuousW_model1, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model1, \"z-value\": z_value_driv_continuousW_model1, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model1, \"p_value_corrected\": p_value_BH_driv_continuousW_model1[1]})\n",
    "\n",
    "# model 3\n",
    "point_driv_lb_continuousW_model3, point_driv_ub_continuousW_model3 = est_driv_continuousW_model3.effect_interval(X_model3_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_continuousW_model3 = point_driv_continuousW_model3/((point_driv_ub_continuousW_model3-point_driv_lb_continuousW_model3)/(2*1.96))\n",
    "p_value_driv_continuousW_model3 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model3)) # * 2\n",
    "p_value_BH_driv_continuousW_model3 = multipletests(pvals = p_value_driv_continuousW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_continuousW_model3, \"upper_bound\": point_driv_ub_continuousW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model3, \"z-value\": z_value_driv_continuousW_model3, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model3, \"p_value_corrected\": p_value_BH_driv_continuousW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_continuousW_model3.loc[full_results_continuousW_model3[\"p_value\"] < 0.05, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_driv_lb_binaryW_model1, point_driv_ub_binaryW_model1 = est_driv_binaryW_model1.effect_interval(X_model1_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model1 = point_driv_binaryW_model1/((point_driv_ub_binaryW_model1-point_driv_lb_binaryW_model1)/(2*1.96))\n",
    "p_value_driv_binaryW_model1 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model1)) # * 2\n",
    "p_value_BH_driv_binaryW_model1 = multipletests(pvals = p_value_driv_binaryW_model1, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model1 = pd.DataFrame({\"IID\": selected_id_set1_arr, \"point\": point_driv_binaryW_model1, \"upper_bound\": point_driv_ub_binaryW_model1, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model1, \"z-value\": z_value_driv_binaryW_model1, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model1, \"p_value_corrected\": p_value_BH_driv_binaryW_model1[1]})\n",
    "\n",
    "# model 2\n",
    "point_driv_lb_binaryW_model2, point_driv_ub_binaryW_model2 = est_driv_binaryW_model2.effect_interval(X_model2_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model2 = point_driv_binaryW_model2/((point_driv_ub_binaryW_model2-point_driv_lb_binaryW_model2)/(2*1.96))\n",
    "p_value_driv_binaryW_model2 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model2)) # * 2\n",
    "p_value_BH_driv_binaryW_model2 = multipletests(pvals = p_value_driv_binaryW_model2, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model2 = pd.DataFrame({\"IID\": selected_id_set2_arr, \"point\": point_driv_binaryW_model2, \"upper_bound\": point_driv_ub_binaryW_model2, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model2, \"z-value\": z_value_driv_binaryW_model2, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model2, \"p_value_corrected\": p_value_BH_driv_binaryW_model2[1]})\n",
    "\n",
    "# model 3\n",
    "point_driv_lb_binaryW_model3, point_driv_ub_binaryW_model3 = est_driv_binaryW_model3.effect_interval(X_model3_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model3 = point_driv_binaryW_model3/((point_driv_ub_binaryW_model3-point_driv_lb_binaryW_model3)/(2*1.96))\n",
    "p_value_driv_binaryW_model3 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model3)) # * 2\n",
    "p_value_BH_driv_binaryW_model3 = multipletests(pvals = p_value_driv_binaryW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_binaryW_model3, \"upper_bound\": point_driv_ub_binaryW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model3, \"z-value\": z_value_driv_binaryW_model3, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model3, \"p_value_corrected\": p_value_BH_driv_binaryW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_binaryW_model1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_driv_binaryW_model1 = est_driv_binaryW_model1.shap_values(X_model1_mat.iloc[1:100, :])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab36d0f287787cded7684b4262a0997f97d128972c9ea447e9ce26f1cdffaf94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
