{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yujia/miniconda3/envs/mr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import dowhy\n",
    "import econml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import shap\n",
    "import statsmodels.nonparametric.smoothers_lowess as sl\n",
    "from econml.grf import CausalForest, CausalIVForest, RegressionForest\n",
    "from econml.iv.dml import DMLIV, NonParamDMLIV, OrthoIV\n",
    "from econml.iv.dr import DRIV, ForestDRIV, LinearDRIV, SparseLinearDRIV\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCV\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy import special\n",
    "from scipy.interpolate import interp1d, interpn\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import (LinearRegression, LogisticRegression,\n",
    "                                  LogisticRegressionCV)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and sample\n",
    "X_set1 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/04_pheno_covar_data/traits/ukbb.covariate.traits.set1.gz\", sep = \"\\t\")\n",
    "X_set2 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/04_pheno_covar_data/traits/ukbb.covariate.traits.set2.gz\", sep = \"\\t\")\n",
    "X_set3 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/04_pheno_covar_data/TC/CAD/ukbb.covariate.TC.set3.gz\", sep = \"\\t\")\n",
    "\n",
    "Z_set1 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/06_PRS_calculation/TC/CAD/set1/1e-08/TC_prs.best\", sep = \" \") # score_constd\n",
    "Z_set2 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/06_PRS_calculation/TC/CAD/set2/1e-08/TC_prs.best\", sep = \" \") # score_constd\n",
    "Z_set3 = pd.read_csv(\"/home/yujia/Project/2023-07-20-individual_MR/dat/06_PRS_calculation/TC/CAD/set3/1e-08/TC_prs.best\", sep = \" \") # score_constd\n",
    "\n",
    "W = pd.read_csv(\"~/Project/2023-07-20-individual_MR/dat/04_pheno_covar_data/TC/CAD/ukbb.phenotype.TC.mgdL\", sep = \"\\t\")\n",
    "\n",
    "Y_date1 = pd.read_csv(\"~/Project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date1.gz\", sep = \"\\t\")\n",
    "Y_date2 = pd.read_csv(\"~/Project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date2.gz\", sep = \"\\t\")\n",
    "Y_date3 = pd.read_csv(\"~/Project/2023-07-20-individual_MR/dat/03_outcome_data/CAD_outcome_include_comorbid_date3.gz\", sep = \"\\t\")\n",
    "\n",
    "# harmonize the data\n",
    "selected_id_set1 = set.intersection(set(X_set1['IID']), set(Z_set1['IID']), set(W['IID']), set(Y_date1['IID']) )\n",
    "selected_id_set2 = set.intersection(set(X_set2['IID']), set(Z_set2['IID']), set(W['IID']), set(Y_date2['IID']) )\n",
    "selected_id_set3 = set.intersection(set(X_set3['IID']), set(Z_set3['IID']), set(W['IID']), set(Y_date3['IID']) )\n",
    "selected_id_set1 = list(selected_id_set1)\n",
    "selected_id_set2 = list(selected_id_set2)\n",
    "selected_id_set3 = list(selected_id_set3)\n",
    "selected_id_set1_arr = np.array(selected_id_set1)\n",
    "selected_id_set2_arr = np.array(selected_id_set2)\n",
    "selected_id_set3_arr = np.array(selected_id_set3)\n",
    "\n",
    "# model 1\n",
    "X_model1 = X_set1.loc[X_set1['IID'].isin(selected_id_set1)].reset_index(drop = True)\n",
    "Z_model1 = Z_set1.loc[Z_set1['IID'].isin(selected_id_set1)].reset_index(drop = True)\n",
    "W_model1 = W.loc[W['IID'].isin(selected_id_set1)].reset_index(drop = True)\n",
    "Y_model1 = Y_date1.loc[Y_date1['IID'].isin(selected_id_set1)].reset_index(drop = True)\n",
    "\n",
    "# model 2\n",
    "X_model2 = X_set2.loc[X_set2['IID'].isin(selected_id_set2)].reset_index(drop = True)\n",
    "Z_model2 = Z_set2.loc[Z_set2['IID'].isin(selected_id_set2)].reset_index(drop = True)\n",
    "W_model2 = W.loc[W['IID'].isin(selected_id_set2)].reset_index(drop = True)\n",
    "Y_model2 = Y_date2.loc[Y_date2['IID'].isin(selected_id_set2)].reset_index(drop = True)\n",
    "X_model2 = pd.concat([X_model2, Y_model2.loc[:, [\"htn\", \"t2dm\", \"heart_failure\", \"hemorrhage_stroke\", \"ischemic_stroke\"]]], axis=1)\n",
    "Y_model2 = Y_model2.loc[:, [\"IID\", \"CAD\"]]\n",
    "\n",
    "# model 3\n",
    "X_model3 = X_set3.loc[X_set3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "Z_model3 = Z_set3.loc[Z_set3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "W_model3 = W.loc[W['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "Y_model3 = Y_date3.loc[Y_date3['IID'].isin(selected_id_set3)].reset_index(drop = True)\n",
    "X_model3 = pd.concat([X_model3, Y_model3.loc[:, [\"htn\", \"t2dm\", \"heart_failure\", \"hemorrhage_stroke\", \"ischemic_stroke\"]]], axis=1)\n",
    "Y_model3 = Y_model3.loc[:, [\"IID\", \"CAD\"]]\n",
    "\n",
    "# generate mat file for three models\n",
    "# model 1\n",
    "W_model1_mat = W_model1.loc[:, [\"30690-0.0\"]][\"30690-0.0\"]\n",
    "X_model1_mat = X_model1.iloc[:, 2:]\n",
    "Y_model1_mat = Y_model1.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model1_mat = Z_model1.iloc[:, 3]\n",
    "\n",
    "# model 2\n",
    "W_model2_mat = W_model2.loc[:, [\"30690-0.0\"]][\"30690-0.0\"]\n",
    "X_model2_mat = X_model2.iloc[:, 2:]\n",
    "Y_model2_mat = Y_model2.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model2_mat = Z_model2.iloc[:, 3]\n",
    "\n",
    "# model 3\n",
    "W_model3_mat = W_model3.loc[:, [\"30690-0.0\"]][\"30690-0.0\"]\n",
    "X_model3_mat = X_model3.iloc[:, 2:]\n",
    "Y_model3_mat = Y_model3.loc[:, [\"CAD\"]][\"CAD\"]\n",
    "Z_model3_mat = Z_model3.iloc[:, 3]\n",
    "\n",
    "# correct the data type\n",
    "X_model1_mat = X_model1_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64',\n",
    "})\n",
    "\n",
    "X_model2_mat = X_model2_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \n",
    "    \"4079-0.0\": 'float64', \"4080-0.0\": 'float64', \"189-0.0\": 'float64', \n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"whr\": 'float64', \"23099-0.0\": 'float64', \"21001-0.0\": 'float64', \"21002-0.0\": 'float64',\n",
    "    \"Blood_pressure_medication\": 'int64', \"Cholesterol_lowering_medication\": 'int64', \"No_medication\": 'int64', \"Insulin\": 'int64', \n",
    "    \"Non_alcohol_drinker\": 'int64' , \"Previous_alcohol_drinker\": 'int64', \"Current_alcohol_drinker\": 'int64',\n",
    "    \"Non_smoker\": 'int64' , \"Previous_smoker\": 'int64', \"Current_smoker\": 'int64'\n",
    "})\n",
    "\n",
    "X_model3_mat = X_model3_mat.astype({\n",
    "    \"22001-0.0\": 'int64', \"21022-0.0\": 'float64', \n",
    "    \"4079-0.0\": 'float64', \"4080-0.0\": 'float64', \"189-0.0\": 'float64', \n",
    "    \"22009-0.1\": 'float64', \"22009-0.2\": 'float64', \"22009-0.3\": 'float64', \"22009-0.4\": 'float64', \"22009-0.5\": 'float64',\n",
    "    \"22009-0.6\": 'float64', \"22009-0.7\": 'float64', \"22009-0.8\": 'float64', \"22009-0.9\": 'float64', \"22009-0.10\": 'float64', \"22000-0.0\": 'float64',\n",
    "    \"whr\": 'float64', \"23099-0.0\": 'float64', \"21001-0.0\": 'float64', \"21002-0.0\": 'float64',\n",
    "    \"Blood_pressure_medication\": 'int64', \"Cholesterol_lowering_medication\": 'int64', \"No_medication\": 'int64', \"Insulin\": 'int64', \n",
    "    \"Non_alcohol_drinker\": 'int64' , \"Previous_alcohol_drinker\": 'int64', \"Current_alcohol_drinker\": 'int64',\n",
    "    \"Non_smoker\": 'int64' , \"Previous_smoker\": 'int64', \"Current_smoker\": 'int64',\n",
    "    \"30870-0.0\": 'float64', # lipid-related covariates\n",
    "    \"30680-0.0\": 'float64', \"30700-0.0\": 'float64', \"30710-0.0\": 'float64', \"30720-0.0\": 'float64', \"30730-0.0\": 'float64', \n",
    "    \"30740-0.0\": 'float64', \"30750-0.0\": 'float64', \"30650-0.0\": 'float64', \"30660-0.0\": 'float64', \n",
    "    \"30670-0.0\": 'float64', \"30770-0.0\": 'float64', \"30810-0.0\": 'float64', \"30830-0.0\": 'float64', \"30850-0.0\": 'float64', \n",
    "    \"30860-0.0\": 'float64', \"30880-0.0\": 'float64', \"30890-0.0\": 'float64', \"30840-0.0\": 'float64',\n",
    "    \"t2dm\": 'int64', \"htn\": 'int64', \"heart_failure\": 'int64', \"hemorrhage_stroke\": 'int64', \"ischemic_stroke\": 'int64'\n",
    "})\n",
    "\n",
    "# correct the data type\n",
    "X_model1_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age',\n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "}, inplace=True)\n",
    "\n",
    "X_model2_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age', \n",
    "    \"4079-0.0\": 'diastolic blood pressure', \"4080-0.0\": 'systolic blood pressure', \"189-0.0\": 'Townsend deprivation index', \n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "    \"whr\": 'Waist-hip-ratio', \"23099-0.0\": 'Body Fat Percentage', \"21001-0.0\": 'BMI', \"21002-0.0\": 'Weight',\n",
    "    \"Blood_pressure_medication\": 'Blood pressure medication', \"Cholesterol_lowering_medication\": 'Cholesterol lowering medication', \"No_medication\": 'No medication', \"Insulin\": 'Insulin', \n",
    "    \"Non_alcohol_drinker\": 'Non-alcohol drinker' , \"Previous_alcohol_drinker\": 'Previous alcohol drinker', \"Current_alcohol_drinker\": 'Current alcohol drinker',\n",
    "    \"Non_smoker\": 'Non-smoker' , \"Previous_smoker\": 'Previous smoker', \"Current_smoker\": 'Current smoker'\n",
    "}, inplace=True)\n",
    "\n",
    "X_model3_mat.rename({\n",
    "    \"22001-0.0\": 'Gender', \"21022-0.0\": 'Age', \n",
    "    \"4079-0.0\": 'diastolic blood pressure', \"4080-0.0\": 'systolic blood pressure', \"189-0.0\": 'Townsend deprivation index', \n",
    "    \"22009-0.1\": 'PC1', \"22009-0.2\": 'PC2', \"22009-0.3\": 'PC3', \"22009-0.4\": 'PC4', \"22009-0.5\": 'PC5',\n",
    "    \"22009-0.6\": 'PC6', \"22009-0.7\": 'PC7', \"22009-0.8\": 'PC8', \"22009-0.9\": 'PC9', \"22009-0.10\": 'PC10', \"22000-0.0\": 'Genotype batch',\n",
    "    \"whr\": 'Waist-hip-ratio', \"23099-0.0\": 'Body Fat Percentage', \"21001-0.0\": 'BMI', \"21002-0.0\": 'Weight',\n",
    "    \"Blood_pressure_medication\": 'Blood pressure medication', \"Cholesterol_lowering_medication\": 'Cholesterol lowering medication', \"No_medication\": 'No medication', \"Insulin\": 'Insulin', \n",
    "    \"Non_alcohol_drinker\": 'Non-alcohol drinker' , \"Previous_alcohol_drinker\": 'Previous alcohol drinker', \"Current_alcohol_drinker\": 'Current alcohol drinker',\n",
    "    \"Non_smoker\": 'Non-smoker' , \"Previous_smoker\": 'Previous smoker', \"Current_smoker\": 'Current smoker',\n",
    "    \"30870-0.0\": 'Triglycerides', # lipid-related covariates\n",
    "    \"30680-0.0\": 'Calcium', \"30700-0.0\": 'Creatinine', \"30710-0.0\": 'C-reactive protein', \"30720-0.0\": 'Cystatin C', \"30730-0.0\": 'Gamma glutamyltransferase', \n",
    "    \"30740-0.0\": 'Glucose', \"30750-0.0\": 'HbA1c', \"30650-0.0\": 'Aspartate aminotransferase', \"30660-0.0\": 'Direct bilirubin', \n",
    "    \"30670-0.0\": 'Urea', \"30770-0.0\": '30770-0.0', \"30810-0.0\": '30810-0.0', \"30830-0.0\": 'SHBG', \"30850-0.0\": 'Testosterone', \n",
    "    \"30860-0.0\": 'Total protein', \"30880-0.0\": 'Urate', \"30890-0.0\": 'Vitamin D', \"30840-0.0\": 'Total bilirubin',\n",
    "    \"t2dm\": 'Type 2 diabetes history', \"htn\": 'Hypertension history', \"heart_failure\": 'Heart failure history', \"hemorrhage_stroke\": 'Hemorrhage Stroke history', \"ischemic_stroke\": 'Ischemic Stroke history'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_model1_mat_binary = np.where(W_model1_mat <= 220, 1, 0)\n",
    "W_model1_mat_binary = pd.DataFrame({\"30690-0.0\": W_model1_mat_binary}).iloc[:, 0]\n",
    "W_model2_mat_binary = np.where(W_model2_mat <= 220, 1, 0)\n",
    "W_model2_mat_binary = pd.DataFrame({\"30690-0.0\": W_model2_mat_binary}).iloc[:, 0]\n",
    "W_model3_mat_binary = np.where(W_model3_mat <= 220, 1, 0)\n",
    "W_model3_mat_binary = pd.DataFrame({\"30690-0.0\": W_model3_mat_binary}).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRIV estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing\n",
    "train, test = train_test_split(X_model1_mat, test_size=0.5, stratify=Y_model1_mat, random_state=309)\n",
    "train_set = train.index.to_list()\n",
    "test_set = test.index.to_list()\n",
    "train_set.sort()\n",
    "train_set.sort()\n",
    "test_set.sort()\n",
    "\n",
    "# write the training set and testing set to file, which will be used in R analysis.\n",
    "train_set_pd = pd.DataFrame({\"Training_index\": [x+1 for x in train_set], \"Training_id\": selected_id_set1_arr[train_set]})\n",
    "test_set_pd = pd.DataFrame({\"Testing_index\": [x+1 for x in test_set], \"Testing_id\": selected_id_set1_arr[test_set]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous W (Training/Testing Set)\n",
    "est_driv_train_continuousW = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                        n_estimators=5000, min_samples_leaf=50, max_samples=0.02, \n",
    "                                        random_state=309, cov_clip = 1, n_jobs=15)\n",
    "est_driv_train_continuousW.fit(Y_model1_mat[train_set], W_model1_mat[train_set], Z=Z_model1_mat[train_set], X=X_model1_mat.loc[train_set])\n",
    "point_driv_test_continuousW = est_driv_train_continuousW.effect(X_model1_mat.loc[test_set])\n",
    "point_driv_train_continuousW = est_driv_train_continuousW.effect(X_model1_mat.loc[train_set]) \n",
    "print(pd.DataFrame({\"dat\": point_driv_train_continuousW}).describe())\n",
    "print(pd.DataFrame({\"dat\": point_driv_test_continuousW}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  320236.000000\n",
      "mean        0.001246\n",
      "std         0.000333\n",
      "min         0.000428\n",
      "25%         0.000989\n",
      "50%         0.001151\n",
      "75%         0.001476\n",
      "max         0.002433\n"
     ]
    }
   ],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model1 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                         random_state=309, n_jobs=15) \n",
    "est_driv_continuousW_model1.fit(Y_model1_mat, W_model1_mat, Z=Z_model1_mat, X=X_model1_mat, cache_values=True)\n",
    "point_driv_continuousW_model1 = est_driv_continuousW_model1.effect(X_model1_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model1}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dat\n",
      "count  320236.000000\n",
      "mean       -0.105385\n",
      "std         0.015733\n",
      "min        -0.160663\n",
      "25%        -0.116629\n",
      "50%        -0.103409\n",
      "75%        -0.093545\n",
      "max        -0.053157\n"
     ]
    }
   ],
   "source": [
    "est_driv_binaryW_model1 = ForestDRIV(projection=False, discrete_treatment=True, discrete_instrument=False, \n",
    "                                     n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                     random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model1.fit(Y_model1_mat, W_model1_mat_binary, Z=Z_model1_mat, X=X_model1_mat, cache_values=True)\n",
    "point_driv_binaryW_model1 = est_driv_binaryW_model1.effect(X_model1_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model1}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rank_average_treatment_effect():\n",
    "cluster = len(Y_model1_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "320231    0\n",
       "320232    0\n",
       "320233    1\n",
       "320234    0\n",
       "320235    0\n",
       "Name: CAD, Length: 320236, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_model1_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAUCAYAAACEYr13AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAABJ0AAASdAHeZh94AAABZ0lEQVR4nKXTv2/NcRTG8dctgzKQ6CCRCIKuhEgnU/0Y/QM6iBhNXUxPjoEJMUmExcTQiMQuIRKhg61mhgYJIRqNpLmG+x1u7/1+r6FneZKTc96f58nn8+n1+31bqaktbWN7W7OqHuMCDiVZq6qTWMaVJI+GZ3ujEarqFN5hMcmdof4zzOFokt+TItzEL9wf6d/CPlzrdFBVx/ARD5NcbYm2gp04nGSjzcFl9PC0xRk8wQHMd0WYxwbedgDeNHp2DFBVu3AcK0nWOgDvGz3T5mA/tmG1Y1mSn1g3iDEG2Nvojy5AU98x0wb40+iO/wCmh2Y3Ab6OOBmrqprCnqHZTYBVfMPshNNnDa75wxggSR+vMFNVRzoAc42+bHMAS42e7wCcM3gnzycBvmBhdLOqduMiXiT53ApI8hf3cLqqTowwFgxu6PZws+033sUn3Bg6fRrXsZTk9URAknVcwnLzvOEgHmBxdP4f/d9nUyrGfRMAAAAASUVORK5CYII=",
      "text/latex": [
       "$\\displaystyle \\left( \\right)$"
      ],
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_driv_binaryW_model1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.1, 1.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_df = pd.DataFrame({\"tau\": point_driv_continuousW_model1})\n",
    "model1_df = model1_df.set_index(selected_id_set1_arr)\n",
    "model1_x = X_model1_mat.copy()\n",
    "model1_x = model1_x.set_index(selected_id_set1_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_df = model1_df.sort_values(\"tau\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_x = model1_x.loc[model1_df.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"index\":selected_id_set1_arr,  \"dat\": point_driv_continuousW_model1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model2 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                         random_state=309, cov_clip = 10, n_jobs=15) \n",
    "est_driv_continuousW_model2.fit(Y_model2_mat, W_model2_mat, Z=Z_model2_mat, X=X_model2_mat, cache_values=True)\n",
    "point_driv_continuousW_model2 = est_driv_continuousW_model2.effect(X_model2_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model2}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous W (Full Set)\n",
    "est_driv_continuousW_model3 = ForestDRIV(projection=False, discrete_treatment=False, discrete_instrument=False, \\\n",
    "                                  n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                  random_state=309, cov_clip = 5, n_jobs=15) \n",
    "est_driv_continuousW_model3.fit(Y_model3_mat, W_model3_mat, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_continuousW_model3 = est_driv_continuousW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_continuousW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model1 = ForestDRIV(projection=False, discrete_treatment=True, discrete_instrument=False, \n",
    "                                     n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                     random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model1.fit(Y_model1_mat, W_model1_mat_binary, Z=Z_model1_mat, X=X_model1_mat, cache_values=True)\n",
    "point_driv_binaryW_model1 = est_driv_binaryW_model1.effect(X_model1_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model1}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model2 = ForestDRIV(projection=False, discrete_treatment=True, discrete_instrument=False,\n",
    "                                     n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                     random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model2.fit(Y_model2_mat, W_model2_mat_binary, Z=Z_model2_mat, X=X_model2_mat, cache_values=True)\n",
    "point_driv_binaryW_model2 = est_driv_binaryW_model2.effect(X_model2_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model2}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary W (Full Set)\n",
    "est_driv_binaryW_model3 = ForestDRIV(projection=False, discrete_treatment=True, discrete_instrument=False, \\\n",
    "                                         n_estimators=5000, min_samples_leaf=100, max_samples=0.02, \n",
    "                                         random_state=309, cov_clip = 0.1, n_jobs=15) \n",
    "est_driv_binaryW_model3.fit(Y_model3_mat, W_model3_mat_binary, Z=Z_model3_mat, X=X_model3_mat, cache_values=True)\n",
    "point_driv_binaryW_model3 = est_driv_binaryW_model3.effect(X_model3_mat)\n",
    "print(pd.DataFrame({\"dat\": point_driv_binaryW_model3}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_driv_lb_continuousW_model1, point_driv_ub_continuousW_model1 = est_driv_continuousW_model1.effect_interval(X_model1_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_continuousW_model1 = point_driv_continuousW_model1/((point_driv_ub_continuousW_model1-point_driv_lb_continuousW_model1)/(2*1.96))\n",
    "p_value_driv_continuousW_model1 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model1)) # * 2\n",
    "p_value_BH_driv_continuousW_model1 = multipletests(pvals = p_value_driv_continuousW_model1, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model1 = pd.DataFrame({\"IID\": selected_id_set1_arr, \"point\": point_driv_continuousW_model1, \"upper_bound\": point_driv_ub_continuousW_model1, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model1, \"z-value\": z_value_driv_continuousW_model1, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model1, \"p_value_corrected\": p_value_BH_driv_continuousW_model1[1]})\n",
    "\n",
    "# model 2\n",
    "point_driv_lb_continuousW_model2, point_driv_ub_continuousW_model2 = est_driv_continuousW_model2.effect_interval(X_model2_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_continuousW_model2 = point_driv_continuousW_model2/((point_driv_ub_continuousW_model2-point_driv_lb_continuousW_model2)/(2*1.96))\n",
    "p_value_driv_continuousW_model2 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model2)) # * 2\n",
    "p_value_BH_driv_continuousW_model2 = multipletests(pvals = p_value_driv_continuousW_model2, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model2 = pd.DataFrame({\"IID\": selected_id_set2_arr, \"point\": point_driv_continuousW_model2, \"upper_bound\": point_driv_ub_continuousW_model2, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model2, \"z-value\": z_value_driv_continuousW_model2, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model2, \"p_value_corrected\": p_value_BH_driv_continuousW_model2[1]})\n",
    "\n",
    "# model 3\n",
    "point_driv_lb_continuousW_model3, point_driv_ub_continuousW_model3 = est_driv_continuousW_model3.effect_interval(X_model3_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_continuousW_model3 = point_driv_continuousW_model3/((point_driv_ub_continuousW_model3-point_driv_lb_continuousW_model3)/(2*1.96))\n",
    "p_value_driv_continuousW_model3 = scipy.stats.norm.sf(abs(z_value_driv_continuousW_model3)) # * 2\n",
    "p_value_BH_driv_continuousW_model3 = multipletests(pvals = p_value_driv_continuousW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_continuousW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_continuousW_model3, \"upper_bound\": point_driv_ub_continuousW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_continuousW_model3, \"z-value\": z_value_driv_continuousW_model3, \\\n",
    "                                \"p_value\": p_value_driv_continuousW_model3, \"p_value_corrected\": p_value_BH_driv_continuousW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_continuousW_model3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_driv_lb_binaryW_model1, point_driv_ub_binaryW_model1 = est_driv_binaryW_model1.effect_interval(X_model1_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model1 = point_driv_binaryW_model1/((point_driv_ub_binaryW_model1-point_driv_lb_binaryW_model1)/(2*1.96))\n",
    "p_value_driv_binaryW_model1 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model1)) # * 2\n",
    "p_value_BH_driv_binaryW_model1 = multipletests(pvals = p_value_driv_binaryW_model1, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model1 = pd.DataFrame({\"IID\": selected_id_set1_arr, \"point\": point_driv_binaryW_model1, \"upper_bound\": point_driv_ub_binaryW_model1, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model1, \"z-value\": z_value_driv_binaryW_model1, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model1, \"p_value_corrected\": p_value_BH_driv_binaryW_model1[1]})\n",
    "\n",
    "# model 2\n",
    "point_driv_lb_binaryW_model2, point_driv_ub_binaryW_model2 = est_driv_binaryW_model2.effect_interval(X_model2_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model2 = point_driv_binaryW_model2/((point_driv_ub_binaryW_model2-point_driv_lb_binaryW_model2)/(2*1.96))\n",
    "p_value_driv_binaryW_model2 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model2)) # * 2\n",
    "p_value_BH_driv_binaryW_model2 = multipletests(pvals = p_value_driv_binaryW_model2, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model2 = pd.DataFrame({\"IID\": selected_id_set2_arr, \"point\": point_driv_binaryW_model2, \"upper_bound\": point_driv_ub_binaryW_model2, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model2, \"z-value\": z_value_driv_binaryW_model2, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model2, \"p_value_corrected\": p_value_BH_driv_binaryW_model2[1]})\n",
    "\n",
    "# model 3\n",
    "point_driv_lb_binaryW_model3, point_driv_ub_binaryW_model3 = est_driv_binaryW_model3.effect_interval(X_model3_mat, alpha=0.05) # type: ignore\n",
    "z_value_driv_binaryW_model3 = point_driv_binaryW_model3/((point_driv_ub_binaryW_model3-point_driv_lb_binaryW_model3)/(2*1.96))\n",
    "p_value_driv_binaryW_model3 = scipy.stats.norm.sf(abs(z_value_driv_binaryW_model3)) # * 2\n",
    "p_value_BH_driv_binaryW_model3 = multipletests(pvals = p_value_driv_binaryW_model3, method = \"fdr_bh\", alpha=0.1)\n",
    "\n",
    "full_results_binaryW_model3 = pd.DataFrame({\"IID\": selected_id_set3_arr, \"point\": point_driv_binaryW_model3, \"upper_bound\": point_driv_ub_binaryW_model3, \\\n",
    "                                \"lower_bound\": point_driv_lb_binaryW_model3, \"z-value\": z_value_driv_binaryW_model3, \\\n",
    "                                \"p_value\": p_value_driv_binaryW_model3, \"p_value_corrected\": p_value_BH_driv_binaryW_model3[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_binaryW_model1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_driv_binaryW_model1 = est_driv_binaryW_model1.shap_values(X_model1_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab36d0f287787cded7684b4262a0997f97d128972c9ea447e9ce26f1cdffaf94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
